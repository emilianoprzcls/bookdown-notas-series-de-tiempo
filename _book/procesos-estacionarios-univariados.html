<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Capítulo 4 Procesos estacionarios univariados | Notas de Clase: Series de Tiempo</title>
<meta name="author" content="Benjamín Oliva, Omar Alfaro-Rivera y Emiliano Pérez Caullieres">
<meta name="description" content="En este capítulo analizaremos el método o metodología de análisis de series de tiempo propuesto por Box y Jenkins (1970). Los modelos propuestos dentro de está metodología o conjunto de métodos se...">
<meta name="generator" content="bookdown 0.27 with bs4_book()">
<meta property="og:title" content="Capítulo 4 Procesos estacionarios univariados | Notas de Clase: Series de Tiempo">
<meta property="og:type" content="book">
<meta property="og:description" content="En este capítulo analizaremos el método o metodología de análisis de series de tiempo propuesto por Box y Jenkins (1970). Los modelos propuestos dentro de está metodología o conjunto de métodos se...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Capítulo 4 Procesos estacionarios univariados | Notas de Clase: Series de Tiempo">
<meta name="twitter:description" content="En este capítulo analizaremos el método o metodología de análisis de series de tiempo propuesto por Box y Jenkins (1970). Los modelos propuestos dentro de está metodología o conjunto de métodos se...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.0/transition.js"></script><script src="libs/bs3compat-0.3.0/tabs.js"></script><script src="libs/bs3compat-0.3.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Notas de Clase: Series de Tiempo</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Introducción</a></li>
<li><a class="" href="elementos-de-ecuaciones-en-diferencia.html"><span class="header-section-number">2</span> Elementos de Ecuaciones en Diferencia</a></li>
<li><a class="" href="modelos-de-series-de-tiempo-estacionarias.html"><span class="header-section-number">3</span> Modelos de Series de Tiempo Estacionarias</a></li>
<li><a class="active" href="procesos-estacionarios-univariados.html"><span class="header-section-number">4</span> Procesos estacionarios univariados</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="git@github.com:emilianoprzcls/bookdown-notas-series-de-tiempo.git">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="procesos-estacionarios-univariados" class="section level1" number="4">
<h1>
<span class="header-section-number">Capítulo 4</span> Procesos estacionarios univariados<a class="anchor" aria-label="anchor" href="#procesos-estacionarios-univariados"><i class="fas fa-link"></i></a>
</h1>
<p>En este capítulo analizaremos el método o metodología de análisis de series de tiempo propuesto por Box y Jenkins (1970). Los modelos propuestos dentro de está metodología o conjunto de métodos se han vuelto indispensables para efectos de realizar pronósticos de corto plazo.</p>
<p>En este sentido, se analizarán los métodos más importantes en series de tiempo: Autoregresivos (AR) y de Medias Móviles (MA). Asimismo, se realizará un análisis de los procesos que resultan de la combinación de ambos, conocida como ARMA, los cuales son más comúnmente usados para realizar pronósticos.</p>
<div id="procesos-autoregresivos-ar" class="section level2" number="4.1">
<h2>
<span class="header-section-number">4.1</span> Procesos Autoregresivos (AR)<a class="anchor" aria-label="anchor" href="#procesos-autoregresivos-ar"><i class="fas fa-link"></i></a>
</h2>
<p>Los procesos autoregresivos tienen su origen en el trabajo de Cochrane y Orcutt de 1949, mediante el cual analizaron los residuales de una regresión clásica como un proceso autoregresivo. Puede consultarse el apéndice para la discusión del modelo de regresión clásica.</p>
<div id="ar1" class="section level3" number="4.1.1">
<h3>
<span class="header-section-number">4.1.1</span> AR(1)<a class="anchor" aria-label="anchor" href="#ar1"><i class="fas fa-link"></i></a>
</h3>
<p>Como primer caso analizaremos al proceso autoregresivo de primer orden, <span class="math inline">\(AR(1)\)</span>, el cual podemos definir como una Ecuación Lineal en Diferencia Estocástica de Primer Orden. Diremos que una Ecuación Lineal en Diferencia de Primer Orden es estocástica si en su representación analítica considera un componente estocástico como en la ecuación <a href="procesos-estacionarios-univariados.html#eq:EDOEst">(4.1)</a> descrita a continuación:
<span class="math display" id="eq:EDOEst">\[\begin{equation}
    X_t = a_0 + a_1 X_{t-1} + U_t
    \tag{4.1}
\end{equation}\]</span></p>
<p>Donde <span class="math inline">\(a_0\)</span> es un término constante, <span class="math inline">\(U_t\)</span> es un proceso estacionario, con media cero (0), una varianza finita y constante (<span class="math inline">\(\sigma^2\)</span>) y una covarianza que depende de la distancia entre <span class="math inline">\(t\)</span> y cualquier <span class="math inline">\(t-s\)</span> (<span class="math inline">\(\gamma_s\)</span>)–que no depende de los valores pasados o futuros de la variable–, <span class="math inline">\(X_0\)</span> es el valor inicial de <span class="math inline">\(X_t\)</span>. No obstante, en general vamos a asumir que la covarianza será cero (0), por lo que tendremos un proceso puramente aleatorio. Considerando la ecuación <a href="procesos-estacionarios-univariados.html#eq:EDOEst">(4.1)</a> y un proceso de sustitución sucesivo podemos establecer lo siguiente, empezando con <span class="math inline">\(X_1\)</span>:
<span class="math display">\[\begin{eqnarray*}
    X_{1} &amp; = &amp; a_0 + a_1 X_{0} + U_{1}
\end{eqnarray*}\]</span></p>
<p>Para <span class="math inline">\(X_2\)</span>:
<span class="math display">\[\begin{eqnarray*}
X_{2} &amp; = &amp; a_0 + a_1 X_{1} + U_{2} \\
    &amp; = &amp; a_0 + a_1 (a_0 + a_1 X_{0} + U_{1}) + U_{2} \\
    &amp; = &amp; a_0 + a_1 a_0 + a_1^2 X_{0} + a_1 U_{1} + U_{2}
\end{eqnarray*}\]</span></p>
<p>Para <span class="math inline">\(X_3\)</span>:
<span class="math display">\[\begin{eqnarray*}
X_{3} &amp; = &amp; a_0 + \alpha X_{2} + U_{3} \\
    &amp; = &amp; a_0 + a_1 (a_0 + a_1 a_0 + a_1^2 X_{0} + a_1 U_{1} + U_{2}) + U_{3} \\
    &amp; = &amp; a_0 + a_1 a_0 + a_1^2 a_0 + a_1^3 X_{0} + a_1^2 U_{1} + a_1 U_{2} + U_{3}
\end{eqnarray*}\]</span></p>
<p>Así, para cualquier <span class="math inline">\(X_t\)</span>, <span class="math inline">\(t = 1, 2, 3, \ldots\)</span>, obtendríamos:
<span class="math display" id="eq:EDOSSol">\[\begin{eqnarray}
X_{t} &amp; = &amp; a_0 + a_1 X_{t - 1} + U_{t} \nonumber \\
    &amp; = &amp; a_0 + a_1 (a_0 + a_1 a_0 + a_1^2 a_0 + \ldots + a_1^{t-2} a_0 + a_1^{t-1} X_{0} \nonumber \\
    &amp;   &amp; + a_1^{t-2} U_{1} + \ldots + a_1 U_{t - 2} + U_{t - 1}) + U_{t} \nonumber \\
    &amp; = &amp; a_0 + a_1 a_0 + a_1^2 a_0 + a_1^3 a_0 + \ldots + a_1^{t-1} a_0 + a_1^{t} X_{0} \nonumber \\
    &amp;   &amp; + a_1^{t-1} U_{1} + \ldots a_1^2 U_{t - 2} + a_1 U_{t - 1} + U_{t} \nonumber \\
    &amp; = &amp; (1 + a_1 + a_1^2 + a_1^3 + \ldots + a_1^{t-1}) a_0 + a_1^{t} X_{0} \nonumber \\
    &amp;   &amp; + a_1^{t-1} U_{1} + \ldots + a_1^2 U_{t - 2} + a_1 U_{t - 1} + U_{t}  \nonumber\\
    &amp; = &amp; \frac{1 - a_1^t}{1 - a_1} a_0 + a_1^{t} X_{0} + \sum^{t-1}_{j = 0} a_1^{j} U_{t - j}
    \tag{4.2}
\end{eqnarray}\]</span></p>
<p>De esta forma en la ecuación <a href="procesos-estacionarios-univariados.html#eq:EDOSSol">(4.2)</a> observamos un proceso que es explicado por dos partes: una que depende del tiempo y otra que depende de un proceso estocástico. Asimismo, debe notarse que la condición de convergencia es idéntica que en el caso de ecuaciones en diferencia estudiadas al inicio del curso: <span class="math inline">\(\lvert a_1 \lvert &lt; 1\)</span>, por lo que cuando <span class="math inline">\(t \to \infty\)</span>, la expresión <a href="procesos-estacionarios-univariados.html#eq:EDOSSol">(4.2)</a> será la siguiente:
<span class="math display" id="eq:EDOSLP">\[\begin{equation}
    X_t = \frac{1}{1 - a_1} a_0 + \sum^{\infty}_{j = 0} a_1^{j} U_{t - j}
    \tag{4.3}
\end{equation}\]</span></p>
<p>Así, desaparece la parte dependiente del tiempo y únicamente prevalece la parte que es dependiente del proceso estocástico. Esta es la solución de largo plazo del proceso <span class="math inline">\(AR(1)\)</span>, la cual depende del proceso estocástico. Notemos, además, que esta solución implica que la variable o la serie de tiempo <span class="math inline">\(X_t\)</span> es tambien un proceso estocástico que hereda las propiedades de <span class="math inline">\(U_t\)</span>. Así, <span class="math inline">\(X_t\)</span> es también un proceso estocástico estacionario, como demostraremos más adelante.</p>
<p>Observemos que la ecuación <a href="procesos-estacionarios-univariados.html#eq:EDOSLP">(4.3)</a> se puede reescribir si consideramos la formulación que en la literatura se denomina como la descomposición de Wold, en la cual se define que es posible asumir que <span class="math inline">\(\psi_j = a_1^j\)</span> y se considera el caso en el cual <span class="math inline">\(\lvert a_1 \lvert&lt; 1\)</span>, de esta forma tendremos que por ejemplo cuando:
<span class="math display">\[\begin{equation*}
    \sum^{\infty}_{j = 0} \psi^2_j = \sum^{\infty}_{j = 0} a_1^{2j} = \frac{1}{1 - a_1^2}
\end{equation*}\]</span></p>
<p>Alternativamente y de forma similar a las ecuaciones en diferencia estudiadas previamente podemos escribir el proceso <span class="math inline">\(AR(1)\)</span> mediante el uso del operador rezago como:
<span class="math display" id="eq:AR1">\[\begin{eqnarray}
    X_t &amp; = &amp; a_0 + a_1 L X_t + U_t \nonumber \\
    X_t - a_1 L X_t &amp; = &amp; a_0 + U_t \nonumber \\
    (1 - a_1 L) X_t &amp; = &amp; a_0 + U_t \nonumber \\
    X_t &amp; = &amp; \frac{a_0}{1 - a_1 L} + \frac{1}{1 - a_1 L} U_t
    \tag{4.4}
\end{eqnarray}\]</span></p>
<p>En esta última ecuación retomamos el siguiente término para reescribirlo como:
<span class="math display" id="eq:AR2">\[\begin{equation}
    \frac{1}{1 - a_1 L} = 1 + a_1 L + a_1^2 L^2 + a_1^3 L^3 + \ldots
    \tag{4.5}
\end{equation}\]</span></p>
<p>Tomando este resultado para sustituirlo en ecuación <a href="procesos-estacionarios-univariados.html#eq:AR1">(4.4)</a>, obtenemos la siguiente expresión:
<span class="math display" id="eq:AR1Sol">\[\begin{eqnarray}
X_t &amp; = &amp; (1 + a_1 L + a_1^2 L^2 + a_1^3 L^3 + \ldots) a_0 + (1 + a_1 L + a_1^2 L^2 + a_1^3 L^3 + \ldots) U_t \nonumber \\
    &amp; = &amp; (1 + a_1 + a_1^2 + a_1^3 + \ldots) a_0 + U_t + a_1 U_{t-1} + a_1^2 U_{t-2} + a_1^3 U_{t-3} + \ldots \nonumber \\
    &amp; = &amp; \frac{a_0}{1 - a_1} + \sum^{\infty}_{j = 0} a_1^j U_{t-j}
    \tag{4.6}
\end{eqnarray}\]</span></p>
<p>Donde la condición de convergencia y estabilidad del proceso descrito en esta ecuación es que <span class="math inline">\(\lvert a_1 \lvert &lt; 1\)</span>. Por lo que hemos demostrado que mediante el uso del operador de rezago es posible llegar al mismo resultado que obtuvimos mediante el procedimiento de sustituciones iterativas.</p>
<p>La ecuación <a href="procesos-estacionarios-univariados.html#eq:AR1Sol">(4.6)</a> se puede interpretar como sigue. La solución o trayectoria de equilibrio de un AR(1) se divide en dos partes. La primera es una constante que depende de los valores de <span class="math inline">\(a_0\)</span> y <span class="math inline">\(a_1\)</span>. La segunda parte es la suma ponderada de las desviaciones o errores observados y acumulados en el tiempo hasta el momento <span class="math inline">\(t\)</span>.</p>
<p>Ahora obtendremos los momentos que describen a la serie de tiempo cuando se trata de un porceso <span class="math inline">\(AR(1)\)</span>. Para ello debemos obtener la media, la varianza y las covarianzas de <span class="math inline">\(X_t\)</span>. Para los siguientes resultados debemos recordar y tener en mente que si <span class="math inline">\(U_t\)</span> es un proceso puramente aleatorio, entonces:</p>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(\mathbb{E}[U_t] = 0\)</span> para todo <span class="math inline">\(t\)</span>
</li>
<li>
<span class="math inline">\(Var[U_t] = \sigma^2\)</span> para todo <span class="math inline">\(t\)</span>
</li>
<li>
<span class="math inline">\(Cov[U_t, U_s] = 0\)</span> para todo <span class="math inline">\(t \neq s\)</span>
</li>
</ol>
<p>Dicho lo anterior y partiendo de la ecuación <a href="procesos-estacionarios-univariados.html#eq:AR1Sol">(4.6)</a>, el primer momento o valor esperado de la serie de tiempo será el siguiente:
<span class="math display" id="eq:AR1m1">\[\begin{eqnarray}
\mathbb{E}[X_t] &amp; = &amp; \mathbb{E} \left[ \frac{a_0}{1 - a_1} + \sum^{\infty}_{j = 0} a_1^j U_{t-j} \right] \nonumber \\
    &amp; = &amp; \frac{a_0}{1 - a_1} + \sum^{\infty}_{j = 0} a_1^j \mathbb{E}[U_{t-j}] \nonumber \\
    &amp; = &amp; \frac{a_0}{1 - a_1} = \mu
    \tag{4.7}
\end{eqnarray}\]</span></p>
<p>Respecto de la varianza podemos escribir la siguiente expresión a partir de la ecuación <a href="procesos-estacionarios-univariados.html#eq:AR1Sol">(4.6)</a>:
<span class="math display" id="eq:AR1Var">\[\begin{eqnarray}
Var[X_t] &amp; = &amp; \mathbb{E}[(X_t - \mu)^2] \nonumber \\
    &amp; = &amp; \mathbb{E} \left[ \left( \frac{a_0}{1 - a_1} + \sum^{\infty}_{j = 0} a_1^j U_{t-j} - \frac{a_0}{1 - a_1} \right)^2 \right] \nonumber \\
    &amp; = &amp; \mathbb{E}[(U_{t} + a_1 U_{t-1} + a_1^2 U_{t-2} + a_1^3 U_{t-3} + \ldots)^2] \nonumber \\
    &amp; = &amp; \mathbb{E}[U^2_{t} + a_1^2 U^2_{t-1} + a_1^4 U^2_{t-2} + a_1^6 U^2_{t-3} + \ldots \nonumber \\
    &amp;   &amp; + 2 a_1 U_t U_{t-1} + 2 a_1^2 U_t U_{t-2} + \ldots] \nonumber \\
    &amp; = &amp; \mathbb{E}[U^2_{t}] + a_1^2 \mathbb{E}[U^2_{t-1}] + a_1^4 \mathbb{E}[U^2_{t-2}] + a_1^6 \mathbb{E}[U^2_{t-3}] + \ldots \nonumber \\
    &amp; = &amp; \sigma^2 + a_1^2 \sigma^2 + a_1^4 \sigma^2 + a_1^6 \sigma^2 + \ldots \nonumber \\
    &amp; = &amp; \sigma^2 (1 + a_1^2 + a_1^4 + a_1^6 + \ldots) \nonumber \\
    &amp; = &amp; \sigma^2 \frac{1}{1 - a_1^2} = \gamma(0)
    \tag{4.8}
\end{eqnarray}\]</span></p>
<p>Previo a analizar la covarianza de la serie recordemos que para el proceso puramente aleatorio <span class="math inline">\(U_t\)</span> su varianza y covarianza puede verse como <span class="math inline">\(\mathbb{E}[U_t, U_s] = \sigma^2\)</span>, para <span class="math inline">\(t = s\)</span>, y <span class="math inline">\(\mathbb{E}[U_t, U_s] = 0\)</span>, para cualquier otro caso, respectivamente.</p>
<p>Dicho lo anterior, partiendo de la ecuación <a href="procesos-estacionarios-univariados.html#eq:AR1Sol">(4.6)</a> la covarianza de la serie estará dada por:
<span class="math display" id="eq:AR1Cov">\[\begin{eqnarray}
Cov(X_t, X_{t-\tau}) &amp; = &amp; \mathbb{E}[(X_t - \mu)(X_{t-\tau} - \mu)] \nonumber \\
    &amp; = &amp; \mathbb{E} \left[ \left( \frac{a_0}{1 - a_1} + \sum^{\infty}_{j = 0} a_1^j U_{t-j} - \frac{a_0}{1 - a_1} \right) \right. \nonumber \\
    &amp;   &amp; \left. \times \left( \frac{a_0}{1 - a_1} + \sum^{\infty}_{j = 0} a_1^j U_{t-\tau-j} - \frac{a_0}{1 - a_1} \right) \right] \nonumber \\
    &amp; = &amp; a_1^{\tau} \mathbb{E}[U^2_{t-\tau} + a_1 U^2_{t-\tau-1} + a_1^2 U^2_{t-\tau-2} + a_1^3 U^2_{t-\tau-3} + \ldots] \nonumber \\
    &amp; = &amp; a_1^{\tau} \sigma^2 \frac{1}{1 - a_1^2} = \gamma(\tau)
    \tag{4.9}
\end{eqnarray}\]</span></p>
<p>Notése que con estos resultados en las ecuaciones <a href="procesos-estacionarios-univariados.html#eq:AR1Var">(4.8)</a> y <a href="procesos-estacionarios-univariados.html#eq:AR1Cov">(4.9)</a> podemos construir la función de autocorrelación teórica como sigue:
<span class="math display" id="eq:emi1">\[\begin{eqnarray}
\rho(\tau) &amp; = &amp; \frac{\gamma(\tau)}{\gamma(0)} \nonumber \\
    &amp; = &amp; a_1^\tau
    \tag{4.10}
\end{eqnarray}\]</span></p>
<p>Donde <span class="math inline">\(\tau = 1, 2, 3, \ldots\)</span> y <span class="math inline">\(\lvert a_1 \lvert &lt; 1\)</span>. Este último resultado significa que cuando el proceso autoregresivo es de orden 1 (es decir, AR(1)) la función de autocorrelación teóricamente es igual al parámetro <span class="math inline">\(a_1\)</span> elevado al número de rezagos considerados. No obstante, note que esto no significa que la autocorrelación observada sea como lo expresa en planteamiento anterior. Por el contrario, una observación sencilla mostraría que la autocorrelación observada sería ligeramente distinta a la autocorrelación teórica.</p>
<p>Ahora veámos algunos ejemplos. En el primer ejemplo simularemos una serie y mostraremos el analísis de un proceso construído considerando un proceso puramente aleatorio como componente <span class="math inline">\(U_t\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;El procedimiento e implementación del ejercicio está en el archivo R denominado Clase 4 del repositorio de GitHub.&lt;/p&gt;"><sup>2</sup></a> Por su parte, en un segundo ejemplo aplicaremos el análisis a una serie de tiempo de una variable económica observada.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;El procedimiento e implementación del ejercicio está en el archivo R denominado Clase 5 del repositorio de GitHub.&lt;/p&gt;"><sup>3</sup></a></p>
<p>Para el primer ejemplo consideremos un proceso dado por la forma de un <span class="math inline">\(AR(1)\)</span> como en la ecuación <a href="procesos-estacionarios-univariados.html#eq:AR1">(4.4)</a> cuya solución esta dada por la ecuación <a href="procesos-estacionarios-univariados.html#eq:AR1Sol">(4.6)</a>. En especifico, supongamos que el término o componente estocástico <span class="math inline">\(U_t\)</span> es una serie generada a partir de numeros aleatorios de una función normal con media <span class="math inline">\(0\)</span> y desviación estándar <span class="math inline">\(4\)</span>. Los detalles del proceso simulado se muestra en las siguientes gráficas.</p>
<p>La Figura <a href="procesos-estacionarios-univariados.html#fig:GAR1Real">4.1</a> ilustra el comportamiento que se debería observar en una serie considerando el procedimiento iterativo de construcción. Por su parte, la Figura <a href="procesos-estacionarios-univariados.html#fig:GAR1Teo">4.2</a> ilustra el proceso o trayectoria de la solución de la serie de tiempo. Finalmente, las Figuras <a href="procesos-estacionarios-univariados.html#fig:GAR1FACr">4.3</a> y <a href="procesos-estacionarios-univariados.html#fig:GAR1FACr">4.3</a> muestran el correlograma calculado considerando una función de autocorrelación aplicada al porceso real y una función de autocorrelación aplicada al proceso teórico, respectivamente.</p>
<p>Recordemos que una trayectoria de equilibrio o solución de un <span class="math inline">\(AR(1)\)</span> es como se muestra en la ecuación <a href="procesos-estacionarios-univariados.html#eq:AR1Sol">(4.6)</a>. Así, nuestra serie simulada cumple con la característica de que los errores son más relevantes cuando la serie es corta. Por el contrario, los errores son menos relevantes, cuando la serie es muy larga. La Figura <a href="procesos-estacionarios-univariados.html#fig:GAR1Com">4.5</a> ilustra esta observación de la trayectoria de equilibrio.</p>
<p>Para el segundo ejemplo consideremos una aplicación a una serie de tiempo en especifico: Pasajeros transportados mensualmente en el Sistema de Transporte Colectivo Metro (pasajeros medidos en millones).<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Fuente: INEGI, .&lt;/p&gt;"><sup>4</sup></a></p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:GAR1Real"></span>
<img src="imagenes/G_AR_1_Real.png" alt="." width="100%"><p class="caption">
Figure 4.1: .
</p>
</div>
<blockquote>
<p>Figura <a href="procesos-estacionarios-univariados.html#fig:GAR1Com">4.5</a>: AR(1) considerando <span class="math inline">\(X_t=5+0.9X_{t-1}+U_t\)</span> ; <span class="math inline">\(X_0=50\)</span> y que <span class="math inline">\(U_t\)</span>~<span class="math inline">\(N(0, 4)\)</span> y que <span class="math inline">\(U_t \sim \mathcal{N}(0, 4)\)</span></p>
</blockquote>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:GAR1Teo"></span>
<img src="imagenes/G_AR_1_Teo.png" alt="." width="100%"><p class="caption">
Figure 4.2: .
</p>
</div>
<blockquote>
<p>Figura <a href="procesos-estacionarios-univariados.html#fig:GAR1Teo">4.2</a>: <span class="math inline">\(X_t = \frac{5}{1 - 0.9} + \sum_{j = 0}^{t-1} 0.9^j U_{t-j}\)</span>, y que <span class="math inline">\(U_t \sim \mathcal{N}(0, 4)\)</span>}</p>
</blockquote>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:GAR1FACr"></span>
<img src="imagenes/G_AR_1_FACr.png" alt="." width="100%"><p class="caption">
Figure 4.3: .
</p>
</div>
<blockquote>
<p>Figura <a href="procesos-estacionarios-univariados.html#fig:GAR1FACr">4.3</a>: Función de autocorrelación de un AR(1): <span class="math inline">\(\rho(\tau)=\frac{\gamma(\tau)}{\gamma(0)}\)</span></p>
</blockquote>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:GAR1FACt"></span>
<img src="imagenes/G_AR_1_FACt.png" alt="." width="100%"><p class="caption">
Figure 4.4: .
</p>
</div>
<blockquote>
<p>Figura <a href="procesos-estacionarios-univariados.html#fig:GAR1FACr">4.3</a>: Función de autocorrelación de un AR(1): <span class="math inline">\(\rho(\tau)= a_1^\tau\)</span></p>
</blockquote>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:GAR1Com"></span>
<img src="imagenes/G_AR_1_Comb.png" alt="." width="100%"><p class="caption">
Figure 4.5: .
</p>
</div>
<blockquote>
<p>Figura <a href="procesos-estacionarios-univariados.html#fig:GAR1FACr">4.3</a>: AR(1) considerando en conjunto <span class="math inline">\(X_t = 5 + 0.9 X_{t-1} + U_t\)</span>; <span class="math inline">\(X_0 = 50\)</span> y <span class="math inline">\(X_t = \frac{5}{1 - 0.9} + \sum_{j = 0}^{t-1} 0.9^j U_{t-j}\)</span>, y que <span class="math inline">\(U_t \sim \mathcal{N}(0, 4)\)</span></p>
</blockquote>
<p>A la serie se le aplicará una metodología de estimación dada por el método de Máxima Verosimilitud (ML, por sus siglás en inglés). Antes de realizar el proceso de estimación consideremos una transformación de diferencias logaritmicas, con el objeto de obtener una serie de tiempo expresada en tasas de crecimiento y con un comportamiento parecido a un proceso estacionario.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Las tasas de crecimiento no son porcentuales, para hacerlas porcentuales faltaría multiplicar por 100 a la serie.&lt;/p&gt;"><sup>5</sup></a></p>
<p>Así, para cada una de las series que analicemos en diferencias logaritmicas las expresaremos bajo la siguiente transformación: <span class="math display">\[\begin{equation*}
    DLX_t = log(X_t) - log(X_{t-k})
\end{equation*}\]</span></p>
<p>Donde <span class="math inline">\(k = 1, 2, 3, \ldots\)</span> y <span class="math inline">\(log(.)\)</span> es la función logaritmo natural. Esta expresión se pude interpretar como una tasa de crecimiento puesto que asumimos variaciones pequeñas para las cuales se cumple que: <span class="math inline">\(log(X_t) - log(X_{t-k}) \approx \frac{X_t - X_{t-k}}{X_t}\)</span>.</p>
<p>Primero, al realizar el análisis de una serie de tiempo deberemos decidir si éste se realizará para la serie en niveles o en diferencias. Por convención, decimos que la series esta en niveles si ésta se analiza sin heacerle ninguna transformación o si se analiza aplicando logarimos. Cuando la serie se analiza en diferencias significa que la diferencia se hace sin aplicar logaritmos o aplicando logaritmos. Sin embargo, lo común es hacer un análisis en logaritmos.</p>
<p>Para decidir cómo analizar la serie de pasajeros en el metro de la CDMX en la Figura <a href="procesos-estacionarios-univariados.html#fig:GPaxMetro">4.6</a> se muestra la gráfica de la serie en niveles (sin transformación logaritmica y con transformación logarítmica) y en diferencias logarítmicas mensuales (es decir, con <span class="math inline">\(k = 1\)</span>).</p>
<p>A continuación, estimaremos una <span class="math inline">\(AR(1)\)</span> para la serie en niveles bajo la transformación logaritmica (<span class="math inline">\(PaxLMetro_t\)</span>) y en diferencias logarítmitcas (<span class="math inline">\(PaxDLMetro_t\)</span>). Para el primer caso obtenemos el siguiente resultado:</p>
<p><span class="math display">\[\begin{eqnarray}
PaxLMetro_t  =  4.8190 &amp; + &amp; 0.5916 PaxLMetro_{t-1} \\
    (0.0105) &amp; + &amp; (0.0526) \\
\end{eqnarray}\]</span>
<span class="math display">\[\begin{eqnarray}
\hat{\sigma}^2 &amp; = &amp; 0.004335  y  AIC  =  -602.73
\end{eqnarray}\]</span></p>
<p>Para el segundo caso obtenemos el siguiente resultado:</p>
<p><span class="math display">\[\begin{eqnarray}
PaxDLMetro_t  =  0.0007 &amp; - &amp; 0.6194 PaxDLMetro_{t-1} \\
    (0.0023) &amp; + &amp; (0.0511) \\
\end{eqnarray}\]</span>
<span class="math display">\[\begin{eqnarray}
\hat{\sigma}^2 &amp; = &amp; 0.003344 &amp; y &amp; AIC &amp; = &amp; -660.53
\end{eqnarray}\]</span></p>
<p>En ambos casos observamos que el parámetro asociado al componente AR es significativo y cumple con la restricción de ser en valor absoluto menor a 1, por lo que la solución asociada al procesp será convergente. También en ambos casos se reporta la estadística o Criterio de Información de Akaike (AIC, por sus siglas en inglés), misma que más adelante discutiremos su importancia y aplicación.</p>
</div>
<div id="ar2" class="section level3" number="4.1.2">
<h3>
<span class="header-section-number">4.1.2</span> AR(2)<a class="anchor" aria-label="anchor" href="#ar2"><i class="fas fa-link"></i></a>
</h3>
<p>Una vez analizado el caso de <span class="math inline">\(AR(1)\)</span> analizaremos el caso del <span class="math inline">\(AR(2)\)</span>. La ecuación generalizada del proceso autoregresivo de orden 2 (denotado como <span class="math inline">\(AR(2)\)</span>) puede ser escrito como:
<span class="math display" id="eq:AR2Eq">\[\begin{equation}
    X_t = a_0 + a_1 X_{t-1} + a_2 X_{t-2} + U_t
    \tag{4.11}
\end{equation}\]</span></p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:GPaxMetro"></span>
<img src="imagenes/G_Pax_Metro.png" alt="Pasajeros transportados (Millones) en el metro de la CDM en niveles y en diferencias logaritmicas." width="100%"><p class="caption">
Figure 4.6: Pasajeros transportados (Millones) en el metro de la CDM en niveles y en diferencias logaritmicas.
</p>
</div>
<p>Donde <span class="math inline">\(U_t\)</span> denota un proceso puramente aleatorio con media cero (<span class="math inline">\(0\)</span>), varianza constante (<span class="math inline">\(\sigma^2\)</span>) y autocovarianza cero (<span class="math inline">\(Cov(U_t, U_s) = 0\)</span>, con <span class="math inline">\(t \neq s\)</span>), y un parametro <span class="math inline">\(a_2 \neq 0\)</span>. Así, utilizando el operador rezago podemos reescribir la ecuación <a href="procesos-estacionarios-univariados.html#eq:AR2Eq">(4.11)</a> como:
<span class="math display">\[\begin{eqnarray*}
    X_t - a_1 X_{t-1} - a_2 X_{t-2} &amp; = &amp; a_0 + U_t \\
    (1 - a_1 L^1 - a_2 L^2) X_t &amp; = &amp; a_0 + U_t
\end{eqnarray*}\]</span></p>
<p>Donde, vamos a denotar a <span class="math inline">\(\alpha (L) = (1 - a_1 L^1 - a_2 L^2)\)</span>, y lo llamaremos como un polinomio que depende del operador rezago y que es distinto de cero. De esta forma podemos reescribir a la ecuación <a href="procesos-estacionarios-univariados.html#eq:AR2Eq">(4.11)</a> como:
<span class="math display" id="eq:AR2Eq1">\[\begin{equation}
    \alpha(L) X_t = a_0 + U_t
    \tag{4.12}
\end{equation}\]</span></p>
<p>Ahora, supongamos que existe el inverso multiplicativo del polinomio <span class="math inline">\(\alpha(L)\)</span>, el cual será denotado como: <span class="math inline">\(\alpha^{-1}(L)\)</span> y cumple con que:
<span class="math display" id="eq:AR2Eq2">\[\begin{equation}
    \alpha^{-1}(L) \alpha(L) = 1   
      \tag{4.13}
\end{equation}\]</span></p>
<p>Así, podemos escribir la solución a la ecuación <a href="procesos-estacionarios-univariados.html#eq:AR2Eq">(4.11)</a> como:
<span class="math display">\[\begin{equation}
    X_t = \alpha^{-1}(L) \delta + \alpha^{-1}(L) U_t
\end{equation}\]</span></p>
<p>Si utilizamos el hecho que <span class="math inline">\(\alpha^{-1}(L)\)</span> se puede descomponer a través del procedimiento de Wold en un polinomio de forma similar el caso de <span class="math inline">\(AR(1)\)</span>, tenemos que:
<span class="math display" id="eq:AR2Eq3">\[\begin{equation}
    \alpha^{-1}(L) = \psi_0 + \psi_1 L + \psi_2 L^2 + \ldots
      \tag{4.14}
\end{equation}\]</span></p>
<p>Por lo tanto, el inverso multiplicativo <span class="math inline">\(\alpha^{-1}(L)\)</span> se puede ver como:
<span class="math display" id="eq:InvAlpha">\[\begin{equation}
    1 = (1 - a_1 L^1 - a_2 L^2) (\psi_0 + \psi_1 L + \psi_2 L^2 + \ldots)
      \tag{4.15}
\end{equation}\]</span></p>
<p>Desarrollando la ecuación <a href="procesos-estacionarios-univariados.html#eq:InvAlpha">(4.15)</a> tenemos la sigueinte expresión:</p>
<p><span class="math display">\[\begin{eqnarray}
    1 &amp; = &amp; \psi_0 &amp; + &amp; \psi_1 L &amp; + &amp; \psi_2 L^2 &amp; + &amp; \psi_3 L^3 &amp; + &amp; \ldots \\
     &amp;  &amp;  &amp; - &amp; a_1 \psi_0 L &amp; - &amp; a_1 \psi_1 L^2 &amp; - &amp; a_1 \psi_2 L^3 &amp; - &amp; \ldots \\
    &amp; &amp;  &amp;  &amp;  &amp; - &amp; a_2 \psi_0 L^2  &amp; - &amp; a_2 \psi_1 L^3 &amp; - &amp; \ldots
\end{eqnarray}\]</span></p>
<p>Ahora, podemos agrupar todos los términos en función del exponente asociado al operador rezago <span class="math inline">\(L\)</span>. La siguiente es una solución partícular y es una de las múltiples que podrían existir que cumpla con la ecuación <a href="procesos-estacionarios-univariados.html#eq:InvAlpha">(4.15)</a>. Sin embargo, para efectos del análisis sólo necesitamos una de esas soluciones. Utilizaremos las siguientes condiciones que deben cumplirse en una de las posibles soluciones:</p>
<p><span class="math display">\[\begin{eqnarray}
    L^0 : &amp;   &amp; \Rightarrow &amp; \psi_0 = 1 \\
    L : &amp; \psi_1 - a_1 \psi_0 = 0 &amp; \Rightarrow &amp; \psi_1 = a_1$ \\
    L^2 : &amp; \psi_2 - a_1 \psi_1 - a_2 \psi_0 = 0 &amp; \Rightarrow &amp; \psi_2 = a^2_1 + a_2 \\
    L^3 : &amp; \psi_3 - a_1 \psi_2 - a_2 \psi_1 = 0 &amp; \Rightarrow &amp; \psi_3 = a^3_1 + 2 a_1 a_2$ \\
    \vdots &amp; \vdots &amp; \vdots &amp; \vdots
\end{eqnarray}\]</span></p>
<p>De esta forma podemos observar que en el límite siempre obtendremos una ecuación del tipo <span class="math inline">\(\psi_j - a_1 \psi_{j-1} - a_2 \psi_{j-2} = 0\)</span> asociada a cada uno de los casos en que exista un <span class="math inline">\(L^j\)</span>, donde <span class="math inline">\(j \neq 0, 1\)</span>, y la cual siempre podremos resolver conociendo que las condiciones iniciales son: <span class="math inline">\(\psi_0 = 1\)</span> y <span class="math inline">\(\psi_1 = a_1\)</span>.</p>
<p>Así, de las relaciones antes mencionadas y considerando que <span class="math inline">\(\alpha^{-1} (L)\)</span> aplicada a una constante como <span class="math inline">\(a_0\)</span>, tendrá como resultado otra constante. De esta forma podemos escribir que la solución del proceso AR(2) en la ecuación <a href="procesos-estacionarios-univariados.html#eq:AR2Eq">(4.11)</a> será dada por una expresión como sigue:
<span class="math display" id="eq:AR2EqSol">\[\begin{equation}
    X_t = \frac{\delta}{1 - a_1 - a_2} + \sum^{\infty}_{j = 0} \psi_{t - j} U_{t - j}
    \tag{4.16}
\end{equation}\]</span></p>
<p>Donde todos los parametros <span class="math inline">\(\psi_i\)</span> está determinado por los parámtros <span class="math inline">\(a_0\)</span>, <span class="math inline">\(a_1\)</span> y <span class="math inline">\(a_2\)</span>. En particular, <span class="math inline">\(\psi_0 = 1\)</span> y <span class="math inline">\(\psi_1 = a_1\)</span> como describimos anteriormente. Al igual que en el caso del <span class="math inline">\(AR(1)\)</span>, en la ecuación <a href="procesos-estacionarios-univariados.html#eq:AR2EqSol">(4.16)</a> las condiciones de estabilidad estarán dadas por las soluciones del siguiente polinomio característico:<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Note que raíces son equivalentes al inversio de las del polinomio dado por &lt;span class="math inline"&gt;\(\lambda^2 a_2 - \lambda a_1 - 1 = 0\)&lt;/span&gt;.&lt;/p&gt;'><sup>6</sup></a>
<span class="math display" id="eq:AR2EqSol1">\[\begin{equation}
    \lambda^2 - \lambda a_1 - a_2 = 0
    \tag{4.17}
\end{equation}\]</span></p>
<p>Así, la condición de estabilidad de la trayectoria es que <span class="math inline">\(\lvert\lambda_i\lvert &lt; 1\)</span>, para <span class="math inline">\(i = 1, 2\)</span>. Es decir, es necesario que cada una de las raíces sea, en valor absoluto, siempre menor que la unidad. Estas son las condiciones de estabilidad para el proceso <span class="math inline">\(AR(2)\)</span>.</p>
<p>Finalmente, al igual que en un <span class="math inline">\(AR(1)\)</span>, a continuación determinamos los momentos de una serie que sigue un proceso <span class="math inline">\(AR(2)\)</span>. Iniciamos con la determinación de la media de la serie:
<span class="math display" id="eq:AR2EqSol2">\[\begin{equation}
    \mathbb{E}[X_t] = \mu = \frac{a_0}{1 - a_1 - a_2}
    \tag{4.18}
\end{equation}\]</span></p>
<p>Lo anterior es cierto puesto que <span class="math inline">\(\mathbb{E}[U_{t - i}] = 0\)</span>, para todo <span class="math inline">\(i = 0, 1, 2, \ldots\)</span>. Para determinar la varianza utilizaremos las siguientes relaciones basadas en el uso del valor esperado, varianza y covarianza de la serie. Adicionalmente, para simplificar el trabajo asumamos que <span class="math inline">\(a_0 = 0\)</span>, lo cual implica que <span class="math inline">\(\mu = 0\)</span>. Dicho lo anterior, partamos de:
<span class="math display" id="eq:AR2EqSol3">\[\begin{eqnarray}
    \mathbb{E}[X_t X_{t - \tau}] &amp; = &amp; \mathbb{E}[(a_1 X_{t-1} + a_2 X_{t-2} + U_t) X_{t - \tau}]\\
    &amp; = &amp; a_1 \mathbb{E}[X_{t - 1} X_{t - \tau}] + a_2 \mathbb{E}[X_{t - 2} X_{t - \tau}] + \mathbb{E}[U_{t} X_{t - \tau}]
    \tag{4.19}
\end{eqnarray}\]</span></p>
<p>Donde <span class="math inline">\(\tau = 0, 1, 2, 3, \ldots\)</span> y que <span class="math inline">\(\mathbb{E}[U_{t} X_{t - \tau}] = 0\)</span> para todo <span class="math inline">\(\tau \neq 0\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Es fácil demostrar está afirmación, sólo requiere de desarrollar la expresión y utilizar el hecho de que &lt;span class="math inline"&gt;\(U_t\)&lt;/span&gt; es un proceso pueramente aleatorio, por lo que la covarianza es cero (0).&lt;/p&gt;'><sup>7</sup></a> Dicho esto, podemos derivar el valor del valor esperado para diferentes valores de <span class="math inline">\(\tau\)</span>:</p>
<p><span class="math display">\[\begin{eqnarray}
    \tau = 0: &amp; \gamma(0) &amp; = &amp; \alpha_1 \gamma(1) + \alpha_2 \gamma(2) + \sigma^2 \\
    \tau = 1: &amp; \gamma(1) &amp; = &amp; \alpha_1 \gamma(0) + \alpha_2 \gamma(1) \\
    \tau = 2: &amp; \gamma(2) &amp; = &amp; \alpha_1 \gamma(1) + \alpha_2 \gamma(0) \\
    \vdots &amp; \vdots &amp; \vdots &amp; \vdots
\end{eqnarray}\]</span></p>
<p>Donde debe ser claro que <span class="math inline">\(\mathbb{E}[(X_{t} - \mu)(X_{t - \tau} - \mu)] = \mathbb{E}[X_{t} X_{t - \tau}] = \gamma(\tau)\)</span>. Así, en general cuando <span class="math inline">\(\tau \neq 0\)</span>:
<span class="math display">\[\begin{equation}
    \gamma(\tau) = a_1 \gamma(\tau - 1) + a_2 \gamma(\tau - 2)
\end{equation}\]</span></p>
<p>Realizando la sustitución recursiva y solucionando el sistema respectivo obtenemos que las varianza y covarianzas estaran determinadas por:
<span class="math display" id="eq:AR2EqSol5">\[\begin{equation}
    Var[X_t] = \gamma(0) = \frac{1 - a_2}{(1 + a_2)[(1 - a_2)^2 - a^2_1]} \sigma^2
    \tag{4.20}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:AR2EqSol6">\[\begin{equation}
    \gamma(1) = \frac{a_1}{(1 + a_2)[(1 - a_2)^2 - a^2_1]} \sigma^2
    \tag{4.21}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:AR2EqSol7">\[\begin{equation}
    \gamma(2) = \frac{a^2_1 + a_2 - a^2_2}{(1 + a_2)[(1 - a_2)^2 - a^2_1]} \sigma^2
    \tag{4.22}
\end{equation}\]</span></p>
<p>Recordemos que las funciones de autocorrelación se obtienen de la división de cada unas de las funciones de covarianza (<span class="math inline">\(\gamma(\tau)\)</span>) por la varianza (<span class="math inline">\(\gamma(0)\)</span>). Así, podemos construir la siguiente expresión:
<span class="math display" id="eq:AR2EqSol8">\[\begin{equation}
    \rho(\tau) - a_1 \rho(\tau - 1) - a_2 \rho(\tau - 2) = 0
    \tag{4.23}
\end{equation}\]</span></p>
<p>Ahora veámos un ejemplo. Utilizaremos la serie de Pasajeros en vuelos nacionales (en vuelos de salidas) para estimar un <span class="math inline">\(AR(2)\)</span> mediante el método de máxima verosimilitud (ML, por sus siglas en inglés). Antes de realizar el proceso de estimación consideremos una transformación de la serie en logaritmos y una más en diferencias logarítmicas; lo anterior con el objeto de obtener un conjunto de series de tiempo suavizada y expresada en tasas de crecimiento, con un comportamiento parecido a un proceso estacionario.</p>
<p>Así, para cada una de las series que analicemos en diferencias logarítmicas las expresaremos bajo la siguiente transformación:
<span class="math display">\[\begin{equation*}
    DLX_t = log(X_t) - log(X_{t-k})
\end{equation*}\]</span></p>
<p>Donde <span class="math inline">\(k = 1, 2, 3, \ldots\)</span> y <span class="math inline">\(log(.)\)</span> es la función logaritmo natural. Por convención, decimos que la serie está en niveles si ésta se analiza sin heacerle ninguna transformación o se analiza en logarimos. Cuando la serie se analiza en diferencias significa que la diferencia se hace sin aplicar logaritmos. Y cuando la serie analizada está en diferenncias logarítmicas también diremos que esta en diferencias. Sin embargo, lo común es hacer un análisis en logaritmos y en difereencias logarítmicas.</p>
<p>Primero, para decidir si se realizará un AR(2) para la serie en niveles o en diferencias analizaremos su gráfica. La serie en niveles, en niveles bajo una transformación logarítmica y en diferencias logarítmicas mensuales de los pasajeros en vuelos nacionales se muestra en la Figura <a href="procesos-estacionarios-univariados.html#fig:GPaxNal">4.7</a>.</p>
<p>A continuación, estimaremos un <span class="math inline">\(AR(2)\)</span> para la serie en niveles bajo una transformación logarítmica (<span class="math inline">\(LPaxNal_t\)</span>) y en diferencias logarítmitcas (<span class="math inline">\(DLPax_Nal_t\)</span>). Para el primer caso obtenemos el siguiente resultado:</p>
<p><span class="math display">\[\begin{eqnarray}
    LPaxNal_t &amp; = &amp; 14.6267 &amp; + &amp; 0.7637  &amp; LPaxNal_{t-1} \\
    &amp;  &amp; (0.1816) &amp;  &amp; (0.0637) &amp; \\
    &amp;  &amp;  &amp; + &amp; 0.2025 &amp; LPaxNal_{t-2} \\
    &amp;  &amp;  &amp;  &amp; (0.0646) &amp;
\end{eqnarray}\]</span>
<span class="math display">\[\begin{eqnarray}
\hat{\sigma}^2 &amp; = &amp; 0.01138 &amp; y &amp; AIC &amp; = &amp; -372.64
\end{eqnarray}\]</span></p>
<p>Para el segundo caso obtenemos el siguiente resultado:
<span class="math display">\[\begin{eqnarray}
    DLPaxNal_t &amp; = &amp; 0.0050 &amp; - &amp; 0.3205  &amp; DLPaxNal_{t-1} \\
    &amp;  &amp; (0.0036) &amp;  &amp; (0.0592) &amp; \\
    &amp;  &amp;  &amp; - &amp; 0.4242 &amp; DLPaxNal_{t-2} \\
    &amp;  &amp;  &amp;  &amp; (0.0591) &amp;
\end{eqnarray}\]</span>
<span class="math display">\[\begin{eqnarray}
\hat{\sigma}^2 &amp; = &amp; 0.009378 &amp; y &amp; AIC &amp; = &amp; -418.3
\end{eqnarray}\]</span></p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:GPaxNal"></span>
<img src="imagenes/G_Pax_Nal.png" alt="Pasajeros transportados (Millones) en el metro de la CDM en niveles y en diferencias logaritmicas." width="100%"><p class="caption">
Figure 4.7: Pasajeros transportados (Millones) en el metro de la CDM en niveles y en diferencias logaritmicas.
</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:GRootsAR2"></span>
<img src="imagenes/G_Roots_AR2.png" alt="Inverso de las Raíces del polinomio característico." width="100%"><p class="caption">
Figure 4.8: Inverso de las Raíces del polinomio característico.
</p>
</div>
<p>Para ambos casos entre parentésis indicamos los errores estándar y reportamos el estadístico de Akaike, AIC. Finalmente, podemos determinar si las soluciones serán convergentes, para ello en la Figura <a href="procesos-estacionarios-univariados.html#fig:GRootsAR2">4.8</a> mostramos las raíces asociadas a cada uno de los polinomios. De la inspección visual podemos concluir que ambas propuesta de AR(2) representan una solución convergente y estable.</p>
</div>
<div id="arp" class="section level3" number="4.1.3">
<h3>
<span class="header-section-number">4.1.3</span> AR(p)<a class="anchor" aria-label="anchor" href="#arp"><i class="fas fa-link"></i></a>
</h3>
<p>Veremos ahora una generalización de los procesos autoregresivos (AR). Esta generalización es conocida como un proceso <span class="math inline">\(AR(p)\)</span> y que puede ser descrito por la siguiente ecuación en diferencia estocástica:
<span class="math display" id="eq:ARpEq">\[\begin{equation}
    X_t = a_0 + a_1 X_{t-1} + a_2 X_{t-2} + a_3 X_{t-3} + \ldots + a_p X_{t-p} + U_t
    \tag{4.24}
\end{equation}\]</span></p>
<p>Donde <span class="math inline">\(a_p \neq 0\)</span>, y <span class="math inline">\(U_t\)</span> es un proceso puramente aleatorio con media cero (0), varianza constante (<span class="math inline">\(\sigma^2\)</span>) y covarianza cero (0). Usando el operador rezago, <span class="math inline">\(L^k\)</span>, para <span class="math inline">\(k = 0, 1, 2, \ldots, p\)</span>, obtenemos la siguiente expresión de la ecuación <a href="procesos-estacionarios-univariados.html#eq:ARpEq">(4.24)</a>:
<span class="math display" id="eq:ARpEq1">\[\begin{equation}
    (1 - a_1 L - a_2 L^2 - a_3 L^3 - \ldots - a_p L^p) X_t = a_0 + U_t
    \tag{4.25}
\end{equation}\]</span></p>
<p>Definamos el polinomio <span class="math inline">\(\alpha(L)\)</span> como:
<span class="math display" id="eq:PolA">\[\begin{equation}
    \alpha(L) = 1 - a_1 L - a_2 L^2 - a_3 L^3 - \ldots - a_p L^p
    \tag{4.26}
\end{equation}\]</span></p>
<p>De forma similar que en los procesos <span class="math inline">\(AR(1)\)</span> y <span class="math inline">\(AR(2)\)</span>, las condiciones de estabilidad del proceso <span class="math inline">\(AR(p)\)</span> estarán dadas por la solución de la ecuación característica:
<span class="math display" id="eq:PolA1">\[\begin{equation}
    \lambda^p - a_1 \lambda^{p-1} - a_2 \lambda^{p-2} - a_3 \lambda^{p-3} - \ldots - a_p = 0
        \tag{4.27}
\end{equation}\]</span></p>
<p>Así, solo si el polinomio anterior tiene raíces cuyo valor absoluto sea menor a uno (<span class="math inline">\(\lvert\lambda_i\lvert &lt; 1\)</span>) y si <span class="math inline">\(1 - a_1 L - a_2 L^2 - a_3 L^3 - \ldots - a_p L^p &lt; 1\)</span> podremos decir que el proceso es convergente y estable. Lo anterior significa que la ecuación <a href="procesos-estacionarios-univariados.html#eq:PolA">(4.26)</a> puede expresarse en términos de la descomposición de Wold o como la suma infinita de términos como:
<span class="math display" id="eq:PolA2">\[\begin{equation}
    \frac{1}{1 - a_1 L  - a_2 L^2 - a_3 L^3  - \ldots - a_p L^p} = \psi_0 + \psi_1 L + \psi_2 L^2 + \psi_3 L^3 + \ldots
\tag{4.28}
\end{equation}\]</span></p>
<p>Donde, por construcción de <span class="math inline">\(\alpha(L) \alpha^{-1}(L) = 1\)</span> implica que <span class="math inline">\(\psi_0 = 1\)</span>. De forma similar a los proceso AR(1) y AR(2), es posible determinar el valor de los coefieentes <span class="math inline">\(\psi_j\)</span> en términos de los coefientes <span class="math inline">\(a_i\)</span>. Así, la solución del proceso <span class="math inline">\(AR(p)\)</span> estará dada por:
<span class="math display" id="eq:ARpEqSol">\[\begin{equation}
    X_t = \frac{a_0}{1 - a_1  - a_2 - a_3  - \ldots - a_p} + \sum^{\infty}_{j = 0} \psi_j U_{t-j}
    \tag{4.29}
\end{equation}\]</span></p>
<p>Considerando la solución de la ecuación <a href="procesos-estacionarios-univariados.html#eq:ARpEq">(4.24)</a> expresada en la ecuación <a href="procesos-estacionarios-univariados.html#eq:ARpEqSol">(4.29)</a> podemos determinar los momentos del proceso y que estarán dados por una media como:
<span class="math display" id="eq:ARpEqSol1">\[\begin{equation}
    \mathbb{E}[X_t] = \mu = \frac{a_o}{1 - a_1  - a_2 - a_3  - \ldots - a_p}
        \tag{4.30}
\end{equation}\]</span></p>
<p>Lo anterior, considerado que <span class="math inline">\(\mathbb{E}[U_t] = 0\)</span>, para todo <span class="math inline">\(t\)</span>. Para determinar la varianza del proceso, sin pérdida de generalidad, podemos definir una ecuación: <span class="math inline">\(\gamma(\tau) = \mathbb{E}[X_{t - \tau} X_t]\)</span>, la cual (omitiendo la constante, ya que la correlación de una constante con cuaquier variable aleatoria que depende del tiempo es cero (0)) puede ser escrita como:
<span class="math display" id="eq:ARpEqSol2">\[\begin{equation}
    \gamma(\tau) = \mathbb{E}[(X_{t - \tau}) \cdot (a_1 X_{t-1} + a_2 X_{t-2} + a_3 X_{t-3} + \ldots + + a_p X_{t-p} + U_t)]
        \tag{4.31}
\end{equation}\]</span></p>
<p>Donde <span class="math inline">\(\tau = 0, 1, 2, \ldots, p\)</span> y <span class="math inline">\(a_0 = 0\)</span>, lo que implica que <span class="math inline">\(\mu = 0\)</span>. De lo anterior obtenemos el siguiente conjunto de ecuaciones mediante sustituciones de los valores de <span class="math inline">\(\tau\)</span>:
<span class="math display">\[\begin{eqnarray}
    \gamma(0) &amp; = &amp; a_1 \gamma(1) + a_2 \gamma(2) + \ldots + a_p \gamma(p) + \sigma^2 \nonumber \\
    \gamma(1) &amp; = &amp; a_1 \gamma(0) + a_2 \gamma(1) + \ldots + a_p \gamma(p-1) \nonumber \\
    \vdots \nonumber \\
    \gamma(p) &amp; = &amp; a_1 \gamma(p-1) + a_2 \gamma(p-2) + \ldots + a_p \gamma(0) \nonumber
\end{eqnarray}\]</span></p>
<p>De esta forma, es fácil observar que la ecuación general para <span class="math inline">\(p &gt; 0\)</span> estará dada por:
<span class="math display" id="eq:Gammap">\[\begin{equation}
    \gamma(p) - a_1 \gamma(\tau - 1) - a_2 \gamma(\tau - 2) - \ldots - a_p \gamma(\tau - p) = 0
    \tag{4.32}
\end{equation}\]</span></p>
<p>Dividiendo la ecuación <a href="procesos-estacionarios-univariados.html#eq:Gammap">(4.32)</a> por <span class="math inline">\(\gamma(0)\)</span>, se obtiene la siguiente ecuación:
<span class="math display" id="eq:Gammap1">\[\begin{equation}
    \rho(p) - a_1 \rho(\tau - 1) + a_2 \rho(\tau - 2) + \ldots + a_p \rho(\tau - p) = 0
        \tag{4.33}
\end{equation}\]</span></p>
<p>Así, podemos escribir el siguiente sistema de ecuaciones:
<span class="math display">\[\begin{eqnarray}
    \rho(1) &amp; = &amp; a_1 + a_2 \rho(1) + a_3 \rho(2) + \ldots + a_p \rho(p-1) \nonumber \\
    \rho(2) &amp; = &amp; a_1 \rho(1) + a_2 + a_3 \rho(1) + \ldots + a_p \rho(p-2) \nonumber \\
    &amp; \vdots &amp; \nonumber \\
    \rho(p) &amp; = &amp; a_1 \rho(p-1) + a_2 \rho(p-2) + \ldots + a_p \nonumber
\end{eqnarray}\]</span></p>
<p>Lo anterior se puede expresar como un conjunto de vectores y matrices de la siguiente forma:
<span class="math display" id="eq:Gammap2">\[\begin{equation}
    \left[
    \begin{array}{c}
        \rho(1) \\
        \rho(2) \\
        \vdots \\
        \rho(p)
    \end{array}
    \right]
    =
    \left[
    \begin{array}{c c c c}
        1 &amp; \rho(1) &amp; \ldots &amp; \rho(p - 1) \\
        \rho(1) &amp; 1 &amp; \ldots &amp; \rho(p - 2) \\
        \rho(2) &amp; \rho(1) &amp; \ldots &amp; \rho(p - 3) \\
        \vdots &amp; \vdots &amp; \ldots &amp; \vdots \\
        \rho(p - 1) &amp; \rho(p - 2) &amp; \ldots &amp; 1 \\
    \end{array}
    \right]
    \left[
    \begin{array}{c}
        a_1 \\
        a_2 \\
        a_3 \\
        \vdots \\
        a_p \\
    \end{array}
    \right]
\tag{4.34}
\end{equation}\]</span></p>
<p>De lo anterior podemos escribir la siguiente ecuación que es una forma alternativa para expresar los valores de los coefientes <span class="math inline">\(a_i\)</span> de la la solución del proceso <span class="math inline">\(AR(p)\)</span>:
<span class="math display" id="eq:Gammap3">\[\begin{equation}
    \mathbf{\rho} = \mathbf{R} \mathbf{a}
  \tag{4.35}
\end{equation}\]</span></p>
<p>Es decir, podemos obtener la siguiente expresión:
<span class="math display" id="eq:Gammap4">\[\begin{equation}
    \mathbf{a} = \mathbf{R}^{-1} \mathbf{\rho}
    \tag{4.36}
\end{equation}\]</span></p>
<p>Ahora veámos un ejemplo. Utilizaremos la serie de Pasajeros en vuelos internacionales de salida para estimar un <span class="math inline">\(AR(p)\)</span> mediante el método de máxima verosimilitud (ML). Antes de realizar el proceso de estimación consideremos una transformación de la serie en logaritmos y una más en diferencias logaritmicas; lo anterior con el objeto de obtener un conjunto de series de tiempo suavizada y expresada en tasas de crecimiento, con un comportamiento parecido a un proceso estacionario.</p>
<p>Primero, para decidir si se realizará un <span class="math inline">\(AR(p)\)</span> para la serie en niveles o en diferencias análizaremos su gráfica. La serie de e Pasajeros en vuelos internacionales de salidas se muestra en la Figura <a href="procesos-estacionarios-univariados.html#fig:GPaxInt">4.9</a>. En está se muestra la gráfica de la serie en niveles (sin transformación logaritmica y con transformación logaritmica) y en diferencias logaritmicas mensuales (es decir, con diferencia respecto del mes inmediato anterior).</p>
<p>De la gráfica en la Figura <a href="procesos-estacionarios-univariados.html#fig:GPaxInt">4.9</a> observamos que quizá le mejor forma de estimar un AR(p) es mediante la serie en diferencias, ya que ésta es la que parece ser una serie estacionaria. A continuación, estimaremos una AR(4) para la serie en diferencias logarimitcas (<span class="math inline">\(DLPaxInt_t\)</span>):</p>
<p><span class="math display">\[\begin{eqnarray}
    DLPaxInt_t &amp; = &amp; 0.0050 &amp; - &amp; 0.2701  &amp; DLPaxInt_{t-1} \\
    &amp;  &amp; (0.0052) &amp;  &amp; (0.0655) &amp; \\
    &amp;  &amp;  &amp; - &amp; 0.4326 &amp; DLPaxNal_{t-2} \\
    &amp;  &amp;  &amp;  &amp; (0.0664) &amp; \\
    &amp;  &amp;  &amp; - &amp; 0.1956 &amp; DLPaxNal_{t-3} \\
    &amp;  &amp;  &amp;  &amp; (0.0664) &amp; \\
    &amp;  &amp;  &amp; - &amp; 0.0316 &amp; DLPaxNal_{t-4} \\
    &amp;  &amp;  &amp;  &amp; (0.0653) &amp;
\end{eqnarray}\]</span>
<span class="math display">\[\begin{eqnarray}
\hat{\sigma}^2 &amp; = &amp; 0.02371 &amp; y &amp; AIC &amp; = &amp; -198.16
\end{eqnarray}\]</span></p>
<p>Entre parentésis indicamos los errores estándar y reportamos el estadístico de Akaike, AIC. Finalmente, podemos determinar si las soluciones serán convergentes, para ello en la Figura <a href="procesos-estacionarios-univariados.html#fig:GRootsARp">4.10</a> mostramos las raíces asociadas a cada uno de los polinomios. De la inspección visual podemos concluir que el AR(4) representan una solución convergente y estable.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:GPaxInt"></span>
<img src="imagenes/G_Pax_Int.png" alt="Pasajeros en vuelos internacionales de salida en niveles y en diferencias logaritmicas." width="100%"><p class="caption">
Figure 4.9: Pasajeros en vuelos internacionales de salida en niveles y en diferencias logaritmicas.
</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:GRootsARp"></span>
<img src="imagenes/G_Roots_ARp.png" alt="Inverso de las Raíces del polinomio característico." width="100%"><p class="caption">
Figure 4.10: Inverso de las Raíces del polinomio característico.
</p>
</div>
</div>
</div>
<div id="procesos-de-medias-móviles-ma" class="section level2" number="4.2">
<h2>
<span class="header-section-number">4.2</span> Procesos de Medias Móviles (MA)<a class="anchor" aria-label="anchor" href="#procesos-de-medias-m%C3%B3viles-ma"><i class="fas fa-link"></i></a>
</h2>
<div id="ma1" class="section level3" number="4.2.1">
<h3>
<span class="header-section-number">4.2.1</span> MA(1)<a class="anchor" aria-label="anchor" href="#ma1"><i class="fas fa-link"></i></a>
</h3>
<p>Una vez planteado el proceso generalizado de <span class="math inline">\(AR(p)\)</span>, iniciamos el planteamiento de los proceso de medias móviles, denotados como <span class="math inline">\(MA(q)\)</span>. Iniciemos con el planteamiento del proceso <span class="math inline">\(MA(1)\)</span>, que se puede escribir como una ecuación como la siguiente:
<span class="math display" id="eq:MA1Eq">\[\begin{equation}
    X_t = \mu + U_t - b_1 U_{t-1}
    \tag{4.37}
\end{equation}\]</span></p>
<p>O como:
<span class="math display" id="eq:MA1Eq1">\[\begin{equation}
    X_t - \mu = (1 - b_1 L) U_{t}
    \tag{4.38}
\end{equation}\]</span></p>
<p>Donde <span class="math inline">\(U_t\)</span> es un proceso puramente aleatorio, es decir, con <span class="math inline">\(\mathbb{E}[U_t] = 0\)</span>, <span class="math inline">\(Var[U_t] = \sigma^2\)</span>, y <span class="math inline">\(Cov[U_t, U_s] = 0\)</span>. Así, un proceso <span class="math inline">\(MA(1)\)</span> puede verse como un proceso AR con una descomposición de Wold en la que <span class="math inline">\(\psi_0 = 1\)</span>, <span class="math inline">\(\psi_1 = - b_1\)</span> y <span class="math inline">\(\psi_j = 0\)</span> para todo <span class="math inline">\(j &gt; 1\)</span>.</p>
<p>Al igual que los procesos autoregresivos, determinaremos los momentos de un proceso <span class="math inline">\(MA(1)\)</span>. En el caso de la media observamos que será:
<span class="math display" id="eq:MA1Eq2">\[\begin{eqnarray}
    \mathbb{E}[X_t] &amp; = &amp; \mu + \mathbb{E}[U_t] - b_1 \mathbb{E}[U_{t - 1}] \nonumber \\
    &amp; = &amp; \mu
    \tag{4.39}
\end{eqnarray}\]</span></p>
<p>Por su parte la varianza estará dada por:
<span class="math display" id="eq:MA1Eq3">\[\begin{eqnarray}
    Var[X_t] &amp; = &amp; \mathbb{E}[(X_t - \mu)^2] \nonumber \\
    &amp; = &amp; \mathbb{E}[(U_t - b_1 U_{t-1})^2] \nonumber \\
    &amp; = &amp; \mathbb{E}[U_t^2 - 2 b_1 U_t U_{t-1} + b_1^2 U_{t - 1}^2] \nonumber \\
    &amp; = &amp;\mathbb{E}[U_t^2] - 2 b_1 \mathbb{E}[U_t U_{t-1}] + b_1^2 \mathbb{E}[U_{t - 1}^2]] \nonumber \\
    &amp; = &amp; \sigma^2 + b_1^2 \sigma^2 \nonumber \\
    &amp; = &amp; (1 + b_1^2) \sigma^2 = \gamma(0)
    \tag{4.40}
\end{eqnarray}\]</span></p>
<p>De esta forma, la varianza del proceso es constante en cualquier periodo <span class="math inline">\(t\)</span>. Para determinar la covarianza utilizaremos la siguiente ecuación:
<span class="math display" id="eq:MA1Cov">\[\begin{eqnarray}
    \mathbb{E}[(x_t - \mu)(x_{t + \tau} - \mu)] &amp; = &amp; \mathbb{E}[(U_t - b_1 U_{t-1})(U_{t + \tau} - b_1 U_{t + \tau - 1})] \nonumber \\
    &amp; = &amp; \mathbb{E}[U_t U_{t + \tau} - b_1 U_t U_{t + \tau - 1} - b_1 U_{t - 1} U_{t + \tau} \nonumber \\
    &amp;   &amp; + b_1^2 U_{t - 1} U_{t + \tau - 1}] \nonumber \\
    &amp; = &amp; \mathbb{E}[U_t U_{t + \tau}] - b_1 \mathbb{E}[U_t U_{t + \tau - 1}] \nonumber \\
    &amp;   &amp; - b_1 \mathbb{E}[U_{t - 1} U_{t + \tau}] + b_1^2 \mathbb{E}[U_{t - 1} U_{t + \tau - 1}]
    \tag{4.41}
\end{eqnarray}\]</span></p>
<p>Si hacemos sustituciones de diferentes valores de <span class="math inline">\(\tau\)</span> en la ecuación <a href="procesos-estacionarios-univariados.html#eq:MA1Cov">(4.41)</a> notaremos que la covarianza será distinta de cero únicamente para el caso de <span class="math inline">\(\tau = 1, -1\)</span>. En ambos casos tendremos como resultado:
<span class="math display" id="eq:MA1Cov1">\[\begin{eqnarray}
    \mathbb{E}[(x_t - \mu)(x_{t + 1} - \mu)] &amp; = &amp; \mathbb{E}[(x_t - \mu)(x_{t - 1} - \mu)] \nonumber \\
    &amp; = &amp; - b_1 \mathbb{E}[U_t U_{t}] \nonumber \\
    &amp; = &amp; - b_1 \mathbb{E}[U_{t - 1} U_{t - 1}] \nonumber \\
    &amp; = &amp; - b_1^2 \sigma^2 = \gamma(1)
        \tag{4.42}
\end{eqnarray}\]</span></p>
<p>De esta forma tendremos que las funciones de autocorrelación estarán dadas por los siguientes casos:
<span class="math display">\[\begin{eqnarray}
    \rho(0) &amp; = &amp; 1 \nonumber \\
    \rho(1) &amp; = &amp; \frac{- b_1}{1 + b_1^2} \nonumber \\
    \rho(\tau) &amp; = &amp; 0 \text{ para todo } \tau &gt; 1 \nonumber
\end{eqnarray}\]</span></p>
<p>Ahora regresando a la ecuación <a href="procesos-estacionarios-univariados.html#eq:MA1Eq">(4.37)</a>, su solución la podemos expresar como:
<span class="math display">\[\begin{eqnarray}
    U_ t &amp; = &amp; - \frac{\mu}{1 - b_1} + \frac{1}{1 - b_1 L} X_t \nonumber \\
    &amp; = &amp; - \frac{\mu}{1 - b_1} + X_t + b_1 X_{t-1} + b_1^2 X_{t-2} + \ldots \nonumber
\end{eqnarray}\]</span></p>
<p>Donde la condición para que se cumpla esta ecuación es que <span class="math inline">\(\lvert b_1 \lvert&lt; 1\)</span>. La manera de interpretar esta condición es como una condición de estabilidad de la solución y cómo una condición de invertibilidad. Notemos que un <span class="math inline">\(MA(1)\)</span> (y en general un <span class="math inline">\(MA(q)\)</span>) es equivalente a un <span class="math inline">\(AR(\infty)\)</span>, es decir, cuando se invierte un MA se genera un AR con infinitos rezagos.</p>
<p>En esta sección no desarrollaremos un ejemplo, primero explicaremos en qué consiste una modelación del tipo <span class="math inline">\(MA(q)\)</span> y después platearemos un ejemplo en concreto.</p>
</div>
<div id="maq" class="section level3" number="4.2.2">
<h3>
<span class="header-section-number">4.2.2</span> MA(q)<a class="anchor" aria-label="anchor" href="#maq"><i class="fas fa-link"></i></a>
</h3>
<p>En general, el proceso de medias móviles de orden <span class="math inline">\(q\)</span>, <span class="math inline">\(MA(q)\)</span>, puede ser escrito como:
<span class="math display">\[\begin{equation}
    X_t = \mu + U_t - b_1 U_{t-1} - b_2 U_{t-2} - \ldots - b_q U_{t-q}
    \label{MAq_EQ}
\end{equation}\]</span></p>
<p>Podemos reescribir la ecuación (<span class="math inline">\(\ref{MAq_EQ}\)</span>) utilizando el operador rezago, así tendrémos el proceso de <span class="math inline">\(MA(q)\)</span> como:
<span class="math display">\[\begin{eqnarray}
    X_t - \mu &amp; = &amp; (1 - b_1 L - b_2 L^2 - \ldots - b_q L^q) U_{t} \nonumber \\
    X_t - \mu &amp; = &amp; \beta(L) U_t
    \label{MAq_Red}
\end{eqnarray}\]</span></p>
<p>Donde <span class="math inline">\(U_t\)</span> es un proceso puramente aleatorio con <span class="math inline">\(\mathbb{E}[U_t] = 0\)</span>, <span class="math inline">\(Var[U_t] = \mathbb{E}[U_t^2] = 0\)</span> y <span class="math inline">\(Cov[U_t, U_s] = \mathbb{E}[U_t, U_s] = 0\)</span>, y <span class="math inline">\(\beta(L) = 1 - b_1 L - b_2 L^2 - \ldots - b_q L^q\)</span> es un polinomio del operador rezago <span class="math inline">\(L\)</span>. la ecuación (<span class="math inline">\(\ref{MAq_Red}\)</span>) puede ser interpretada como un proceso <span class="math inline">\(AR(q)\)</span> sobre la serie <span class="math inline">\(U_t\)</span>.</p>
<p>Ahora determinemos los momentos de un proceso <span class="math inline">\(MA(q)\)</span>:
<span class="math display">\[\begin{eqnarray}
    \mathbb{E}[X_t] &amp; = &amp; \mathbb{E}[\mu + U_t - b_1 U_{t-1} - b_2 U_{t-2} - \ldots - b_q U_{t-q}] \nonumber \\
    &amp; = &amp; \mu + \mathbb{E}[U_t] - b_1 \mathbb{E}[U_{t-1}] - b_2 \mathbb{E}[U_{t-2}] - \ldots - b_q \mathbb{E}[U_{t-q}] \nonumber \\
    &amp; = &amp; \mu
\end{eqnarray}\]</span></p>
<p>En el caso de la varianza tenemos que se puede expresar como:
<span class="math display">\[\begin{eqnarray}
    Var[X_t] &amp; = &amp; \mathbb{E}[(X_t - \mu)^2] \nonumber \\
    &amp; = &amp; \mathbb{E}[(U_t - b_1 U_{t-1} - b_2 U_{t-2} - \ldots - b_q U_{t-q})^2] \nonumber \\
    &amp; = &amp; \mathbb{E}[U_t^2 + b_1^2 U_{t-1}^2 + b_2^2 U_{t-2}^2 + \ldots + b_q^2 U_{t-q}^2 \nonumber \\
    &amp;   &amp; - 2 b_1 U_t U_{t - 1} - \ldots - 2 b_{q - 1} b_q U_{t - q + 1} U_{t - q}] \nonumber \\
    &amp; = &amp; \mathbb{E}[U_t^2] + b_1^2 \mathbb{E}[U_{t-1}^2] + b_2^2 \mathbb{E}[U_{t-2}^2] + \ldots + b_q^2 \mathbb{E}[U_{t-q}^2] \nonumber \\
    &amp;   &amp; - 2 b_1 \mathbb{E}[U_t U_{t - 1}] - \ldots - 2 b_{q - 1} b_q \mathbb{E}[U_{t - q + 1} U_{t - q}] \nonumber \\
    &amp; = &amp; \sigma^2 + b^2_1 \sigma^2 + b^2_2 \sigma^2 + \ldots + b^2_q \sigma^2 \nonumber \\
    &amp; = &amp; (1 + b^2_1 + b^2_2 + \ldots + b^2_q) \sigma^2
\end{eqnarray}\]</span></p>
<p>En el caso de las covarianzas podemos utilizar una idea similar al caso del <span class="math inline">\(AR(p)\)</span>, construir una expresión general para cualquier rezago <span class="math inline">\(\tau\)</span>:
<span class="math display">\[\begin{eqnarray}
    Cov[X_t, X_{t + \tau}] &amp; = &amp; \mathbb{E}[(X_t - \mu)(X_{t + \tau} - \mu)] \nonumber \\
    &amp; = &amp; \mathbb{E}[(U_t - b_1 U_{t-1} - b_2 U_{t-2} - \ldots - b_q U_{t-q}) \nonumber \\
    &amp;   &amp; (U_{t + \tau} - b_1 U_{t + \tau -1} - b_2 U_{t + \tau -2} - \ldots - b_q U_{t + \tau - q})] \nonumber
\end{eqnarray}\]</span></p>
<p>La expresión anterior se puede desarrollar para múltiples casos de <span class="math inline">\(\tau = 1, 2, \ldots, q\)</span>. De esta forma tenemos el siguiente sistema:
<span class="math display">\[\begin{eqnarray}
    \tau = 1 &amp; : &amp; \gamma(1) = (- b_1 + b_1 b_2 + \ldots + b_{q-1} b_q) \sigma^2 \nonumber \\
    \tau = 2 &amp; : &amp; \gamma(2) = (- b_2 + b_1 b_3 + \ldots + b_{q-2} b_q) \sigma^2 \nonumber \\
    &amp; \vdots &amp; \nonumber \\
    \tau = q &amp; : &amp; \gamma(q) = b_q \sigma^2 \nonumber
\end{eqnarray}\]</span></p>
<p>Donde <span class="math inline">\(\gamma(\tau) = 0\)</span> para todo <span class="math inline">\(\tau &gt; q\)</span>. Es decir, todas las autocovarianzas y autocorrelaciones con ordenes superiores a <span class="math inline">\(q\)</span> son cero (0). De esta forma, esta caracterítica teórica permite identificar el orden de <span class="math inline">\(MA(q)\)</span> visualizando la función de autocorrelación y verificando a partir de cual valor de rezago la autocorrelación es no significaiva.</p>
<p>Regresando al problema original que es el de determinar una solución para la eucación (<span class="math inline">\(\ref{MAq_EQ}\)</span>), tenemos que dicha solución estará dada por un <span class="math inline">\(AR(\infty)\)</span> en términos de <span class="math inline">\(U_t\)</span>:
<span class="math display">\[\begin{eqnarray}
    U_t &amp; = &amp; - \frac{\mu}{1 - b_1 - b_2 - \ldots - b_q} + \beta(L)^{-1} X_t \nonumber \\
    &amp;   &amp; - \frac{\mu}{1 - b_1 - b_2 - \ldots - b_q} + \sum_{j = 0}^{\infty} c_j X_{t-j}
    \label{MAq_Eq_Sol}
\end{eqnarray}\]</span></p>
<p>Donde se cumple que: <span class="math inline">\(1 = (1 - b_1 L^1 - b_2 L^2 - \ldots - b_q L^q)(1 - c_1 L - c_2 L^2 - \ldots)\)</span> y los coeficientes <span class="math inline">\(c_j\)</span> se pueden determinar por un método de coeficientes indeterminados y en términos de los valores <span class="math inline">\(b_i\)</span>. De igual forma que en el caso de la ecuación (<span class="math inline">\(\ref{ARp_Eq}\)</span>), en la ecuación (<span class="math inline">\(\ref{MAq_Eq_Sol}\)</span>) se deben cumplir condiciones de estabilidad asociadas con las raíces del polinomio carácterististico dado por:
<span class="math display">\[\begin{equation}
    1 - b_1 x - b_2 x^2 - \ldots b_q x^q = 0
\end{equation}\]</span></p>
<p>El cual debe cumplir que <span class="math inline">\(\lvert x_i \lvert &lt; 1\)</span> y que <span class="math inline">\(1 - b_1 - b_2 - \ldots b_q &lt; 1\)</span>.</p>
<p>Ahora veamos un ejemplo del proceso <span class="math inline">\(MA(q)\)</span>, para lo cual retomaremos la serie de Pasajeros transportados en el metro de la CDMX (<span class="math inline">\(PaxMetro\)</span>). Estimaremos el <span class="math inline">\(MA(q)\)</span> mediante el método de máxima verosimilitud (ML). Antes de realizar el proceso de estimación consideremos una transformación de la serie en logaritmos y una más en diferencias logaritmicas; lo anterior con el objeto de obtener un conjunto de series de tiempo suavizada y expresada en tasas de crecimiento, con un comportamiento parecido a un proceso estacionario.</p>
<p>La serie de Pasajeros transportados en el metro de la CDMX se muestra en la Figura <span class="math inline">\(\ref{G_Pax_Metro}\)</span> se muestra la gráfica de la serie en niveles (sin transformación logarítmica y con transformación logarítmica) y en diferencias logarítmicas mensuales (es decir, con una diferencia respecto del mes inmediato anterior). Utilizaremos la serie en diferencias, ya que es la que parece ser estacionaria. Esta serie tiene la peculiaridad de que tiene un salto a la baja y uno al alza entre septiembre de 2017 y octubre de 2017. Para controlar ese efecto, en nuestro modelo <span class="math inline">\(MA(q)\)</span> incluiremos dos variables dummies para dichos meses.</p>
A continuación, estimaremos una <span class="math inline">\(MA(4)\)</span> para la serie en diferencias:
Entre parentésis indicamos los errores estándar y al final reportamos el estadístico de Akaike, AIC. Finalmente, podemos determinar si la solución serán convergente, para ello en la Figura <span class="math inline">\(\ref{G_Roots_MAq}\)</span> mostramos las raíces asociadas a cada uno de los polinomios. De la inspección visual podemos concluir que ambas propuesta de AR(2) representan una solución convergente y estable.
</div>
</div>
<div id="procesos-armap-q-y-arimap-d-q" class="section level2" number="4.3">
<h2>
<span class="header-section-number">4.3</span> Procesos ARMA(p, q) y ARIMA(p, d, q)<a class="anchor" aria-label="anchor" href="#procesos-armap-q-y-arimap-d-q"><i class="fas fa-link"></i></a>
</h2>
<p>Hemos establecido algunas relaciones las de los porcesos AR y los procesos MA, es decir, cómo un <span class="math inline">\(MA(q)\)</span> de la serie <span class="math inline">\(X_t\)</span> puede ser reexpresada como un <span class="math inline">\(AR(\infty)\)</span> de la serie <span class="math inline">\(U_t\)</span>, y viceversa un <span class="math inline">\(AR(p)\)</span> de la serie <span class="math inline">\(X_t\)</span> puede ser reeexpresada como un <span class="math inline">\(MA(\infty)\)</span>.</p>
<p>En este sentido, para cerrar esta sección veámos el caso de la especificación que conjunta ambos modelos en un modelo general conocido como <span class="math inline">\(ARMA(p, q)\)</span> o <span class="math inline">\(ARIMA(p, d, q)\)</span>. La diferencia entre el primero y el segundo es las veces que su tuvo que diferenciar la serie analizada, registro que se lleva en el índice <span class="math inline">\(d\)</span> de los paramétros dentro del concepto <span class="math inline">\(ARIMA(p, d, q)\)</span>. No obstante, en general nos referiremos al modelo como <span class="math inline">\(ARMA(p, q)\)</span> y dependerá del analista si modela la serie en niveles (por ejemplo, en logaritmos) o en diferencias logarítmicas (o diferencias sin logaritmos).</p>
<div id="arma1-1" class="section level3" number="4.3.1">
<h3>
<span class="header-section-number">4.3.1</span> ARMA(1, 1)<a class="anchor" aria-label="anchor" href="#arma1-1"><i class="fas fa-link"></i></a>
</h3>
<p>Dicho lo anterior vamos a empezar con el análisis de un <span class="math inline">\(ARMA(1, 1)\)</span>. Un proceso <span class="math inline">\(ARMA(1, 1)\)</span> puede verse como:
<span class="math display">\[\begin{equation}
    X_t = \delta + a_1 X_{t - 1} + U_t - b_1 U_{t - 1}
    \label{ARMA11_Eq}
\end{equation}\]</span></p>
<p>Aplicando el operado rezago podemos rescribir la ecuación (<span class="math inline">\(\ref{ARMA11_Eq}\)</span>) como:
<span class="math display">\[\begin{equation}
    (1 - a_1 L) X_t = \delta + (1 - b_1 L) U_t
\end{equation}\]</span></p>
<p>Donde <span class="math inline">\(U_t\)</span> es un proceso pueramente aleatorio como en los casos de <span class="math inline">\(AR(p)\)</span> y <span class="math inline">\(MA(q)\)</span>, y <span class="math inline">\(X_t\)</span> puede ser una serie en niveles o en diferencias (ambas, en términos logarítmicos).</p>
<p>Así, el modelo <span class="math inline">\(ARIMA (p, q)\)</span> también tiene una representación de Wold que estará dada por las siguientes expresiones:
<span class="math display">\[\begin{equation}
    X_t = \frac{\delta}{1 - a_1} + \frac{1 - b_1 L}{1 - a_1 L} U_t
    \label{ARMA11_Prev}
\end{equation}\]</span></p>
<p>Donde <span class="math inline">\(a_1 \neq b_1\)</span>, puesto que en caso contrario <span class="math inline">\(X_t\)</span> sería un proceso puramente aleatorio con una media <span class="math inline">\(\mu = \frac{\delta}{1 - a_1}\)</span>. Así, podemos reescribir la descomposición de Wold a partir del componente de la ecuación (<span class="math inline">\(\ref{ARMA11_Prev}\)</span>):
<span class="math display">\[\begin{equation}
    \frac{1 - b_1 L}{1 - a_1 L} = \psi_0 + \psi_1 L + \psi_2 L^2 + \psi_3 L^3 + \ldots
    \label{ARMA11_EQ_Wold}
\end{equation}\]</span></p>
<p>Está ecuación es equivalente a la expresión:
<span class="math display">\[\begin{eqnarray}
    (1 - b_1 L) &amp; = &amp; (1 - a_1 L)(\psi_0 + \psi_1 L + \psi_2 L^2 + \psi_3 L^3 + \ldots) \nonumber \\
    &amp; = &amp; \psi_0 + \psi_1 L + \psi_2 L^2 + \psi_3 L^3 + \ldots \nonumber \\
    &amp;   &amp; - a_1 \psi_0 L - a_1 \psi_1 L^2 - a_2 \psi_2 L^3 - a_1 \psi_3 L^4 - \ldots \nonumber
\end{eqnarray}\]</span></p>
De esta forma podemos establecer el siguiente sistema de coeficientes indeterminados:
<p>Así, la solución a la ecuación (<span class="math inline">\(\ref{ARMA11_Eq}\)</span>) estará dada por la siguiente generalización:
<span class="math display">\[\begin{equation}
    X_t = \frac{\delta}{1 - a_1} + U_t + (a_1 - b_1) U_{t - 1} + a_1(a_1 - b_1) U_{t - 2} + a_1^2(a_1 - b_1) U_{t - 3} + \ldots
    \label{ARMA11_Sol}
\end{equation}\]</span></p>
<p>En la ecuación (<span class="math inline">\(\ref{ARMA11_Sol}\)</span>) las condiciones de estabilidad y de invertibilidad del sistema (de un MA a un AR, y viceversa) estarán dadas por: <span class="math inline">\(\lvert a_1 \lvert &lt; 1\)</span> y <span class="math inline">\(\lvert b_1 \lvert&lt; 1\)</span>. Adicionalmente, la ecuación (<span class="math inline">\(\ref{ARMA11_Sol}\)</span>) expresa cómo una serie que tiene un comportamiento <span class="math inline">\(ARMA(1, 1)\)</span> es equivalente a una serie modelada bajo un <span class="math inline">\(MA(\infty)\)</span>.</p>
<p>Al igual que en los demás modelos, ahora determinaremos los momentos del proceso <span class="math inline">\(ARMA(1, 1)\)</span>. La media estará dada por:
<span class="math display">\[\begin{eqnarray}
    \mathbb{E}[X_t] &amp; = &amp; \mathbb{E}[\delta + a_1 X_{t-1} + U_t - b_1 U_{t-1}] \nonumber \\
    &amp; = &amp; \delta + a_1 \mathbb{E}[X_{t-1}] \nonumber \\
    &amp; = &amp; \frac{\delta}{1 - a_1} \nonumber \\
    &amp; = &amp; \mu
\end{eqnarray}\]</span></p>
<p>Donde hemos utilizado que <span class="math inline">\(\mathbb{E}[X_t] = \mathbb{E}[X_{t-1}] = \mu\)</span>. Es decir, la media de un <span class="math inline">\(ARMA(1, 1)\)</span> es idéntica a la de un <span class="math inline">\(AR(1)\)</span>.</p>
<p>Para determinar la varianza tomaremos una estrategía similar a los casos de <span class="math inline">\(AR(p)\)</span> y <span class="math inline">\(MA(q)\)</span>. Por lo que para todo <span class="math inline">\(\tau \geq 0\)</span>, y suponiendo por simplicidad que <span class="math inline">\(\delta = 0\)</span> (lo que implica que <span class="math inline">\(\mu = 0\)</span>) tendremos:
<span class="math display">\[\begin{eqnarray}
    \mathbb{E}[X_{t-\tau} X_t] &amp; = &amp; \mathbb{E}[(X_{t-\tau}) \cdot (a_1 X_{t-1} + U_t - b_1 U_{t-1})] \nonumber \\
    &amp; = &amp; a_1 \mathbb{E}[X_{t-\tau} X_{t-1}] + \mathbb{E}[X_{t-\tau} U_t] - b_1 \mathbb{E}[X_{t-\tau} U_{t-1}]
    \label{ARMA11_Cov}
\end{eqnarray}\]</span></p>
<p>De la ecuación (<span class="math inline">\(\ref{ARMA11_Cov}\)</span>) podemos determinar una expresión para el caso de <span class="math inline">\(\tau = 0\)</span>:
<span class="math display">\[\begin{eqnarray}
    \mathbb{E}[X_{t} X_t] &amp; = &amp; \gamma(0) \nonumber \\
    &amp; = &amp; a_1 \gamma(1) + \mathbb{E}[U_t X_t] - b_1 \mathbb{E}[X_t U_{t-1}] \nonumber \\
    &amp; = &amp; a_1 \gamma(1) + \sigma^2 + b_1 \mathbb{E}[U_{t-1} (a_1 X_{t-1} + U_t - b_1 U_{t-1})] \nonumber \\
    &amp; = &amp; a_1 \gamma(1) + \sigma^2 - b_1 a_1 \sigma^2 + b_1 \sigma^2 \nonumber \\
    &amp; = &amp; a_1 \gamma(1) + (1 - b_1 (a_1 - b_1)) \sigma^2
\end{eqnarray}\]</span></p>
<p>Para el caso en que <span class="math inline">\(\tau = 1\)</span>:
<span class="math display">\[\begin{eqnarray}
    \mathbb{E}[X_{t-1} X_t] &amp; = &amp; \gamma(1) \nonumber \\
    &amp; = &amp; a_1 \gamma(0) + \mathbb{E}[X_{t-1} U_t] - b_1 \mathbb{E}[X_{t-1} U_{t-1}] \nonumber \\
    &amp; = &amp; a_1 \gamma(0) - b_1 \sigma^2
\end{eqnarray}\]</span></p>
<p>Estas últimas expresiones podemos resolverlas como sistema para determinar los siguientes valores:
<span class="math display">\[\begin{eqnarray}
    \gamma(0) &amp; = &amp; \frac{1 + b_1^2 - 2 a_1 b_1}{1 - a_1^2} \sigma^2 \\
    \gamma(1) &amp; = &amp; \frac{(a_1 - b_1)(1 - a_1 b_1)}{1 - a_1^2} \sigma^2
\end{eqnarray}\]</span></p>
<p>En general para cualquier valor <span class="math inline">\(\tau \geq 2\)</span> tenemos que la autocovarianza y la función de autocorrelación serán:
<span class="math display">\[\begin{eqnarray}
    \gamma(\tau) = a_1 \gamma(\tau - 1) \\
    \rho(\tau) = a_1 \rho(\tau - 1)
\end{eqnarray}\]</span></p>
<p>Por ejemplo, para el caso de <span class="math inline">\(\tau = 1\)</span> tendríamos:
<span class="math display">\[\begin{equation}
    \rho(1) = \frac{(a_1 - b_1)(1 - a_1 b_1)}{1 + b_1^2 - 2 a_1 b_1}
\end{equation}\]</span></p>
<p>De esta forma, la función de autocorrelación oscilará en razón de los valores que tome <span class="math inline">\(a_1\)</span> y <span class="math inline">\(b_1\)</span>.</p>
</div>
<div id="armap-q" class="section level3" number="4.3.2">
<h3>
<span class="header-section-number">4.3.2</span> ARMA(p, q)<a class="anchor" aria-label="anchor" href="#armap-q"><i class="fas fa-link"></i></a>
</h3>
<p>La especificación general de un <span class="math inline">\(ARMA(p, q)\)</span> (donde <span class="math inline">\(p, q \in \mathbb{N}\)</span>) puede ser descrita por la siguiente ecuación:
<span class="math display">\[\begin{eqnarray}
    X_t &amp; = &amp; \delta + a_1 X_{t - 1} + a_2 X_{t - 2} + \ldots + a_p X_{t - p} \nonumber \\
    &amp;   &amp; + U_t - b_1 U_{t - 1} - b_2  U_{t - 2} - \ldots - b_q  U_{t - q}
    \label{ARMApq_Eq}
\end{eqnarray}\]</span></p>
<p>Donde <span class="math inline">\(U_t\)</span> es un proceso puramente aleatorio, y <span class="math inline">\(X_t\)</span> puede ser modelada en niveles o en diferencias (ya sea en logaritmos o sin transformación logarítmica).</p>
<p>Mediante el uso del operador rezago se puede escribir la ecuación (<span class="math inline">\(\ref{ARMApq_Eq}\)</span>) como:
<span class="math display">\[\begin{equation}
    (1 - a_1 L - a_2 L^2 - \ldots - a_p L^p) X_t = \delta + (1 - b_1 L - b_2 L^2 - \ldots - b_q L^q) U_t
    \label{ARMApq_EQLag}
\end{equation}\]</span></p>
<p>En la ecuación (<span class="math inline">\(\ref{ARMApq_EQLag}\)</span>) definamos dos polinomios: <span class="math inline">\(\alpha(L) = (1 - a_1 L - a_2 L^2 - \ldots - a_p L^p)\)</span> y <span class="math inline">\(\beta(L) = (1 - b_1 L - b_2 L^2 - \ldots - b_q L^q)\)</span>. Así, podemos reescribir la ecuación (<span class="math inline">\(\ref{ARMApq_EQLag}\)</span>) como:
<span class="math display">\[\begin{equation}
    \alpha(L) X_t = \delta + \beta(L) U_t
\end{equation}\]</span></p>
<p>Asumiendo que existe el polinomio inverso tal que: <span class="math inline">\(\alpha(L)^{-1}\alpha(L) = 1\)</span>.La solución entonces puede ser escrita como:
<span class="math display">\[\begin{eqnarray}
    X_t &amp; = &amp; \alpha(L)^{-1} \delta + \alpha(L)^{-1} \beta(L) U_t \nonumber \\
    &amp; = &amp; \frac{\delta}{1 - a_1 - a_2 - \ldots - a_p} + \frac{\beta(L)}{\alpha(L)} U_t \nonumber \\
    &amp; = &amp; \frac{\delta}{1 - a_1 - a_2 - \ldots - a_p} + U_t + \psi_1 L U_t + \psi_2 L^2 U_t + \ldots
    \label{ARMApq_Wold}
\end{eqnarray}\]</span></p>
<p>Donde la ecuación (<span class="math inline">\(\ref{ARMApq_Wold}\)</span>) nos permite interpretar que un ARMA(p, q) se puede reexpresar e interpreetar como un <span class="math inline">\(MA(\infty)\)</span> y donde las condiciones para la estabilidad de la solución y la invertibilidad es que las ráices de los polinomios característicos <span class="math inline">\(\alpha(L)\)</span> y <span class="math inline">\(\beta(L)\)</span> son en valor absoluto menores a 1.</p>
<p>Adicionalmente, la fracción en la ecuación (<span class="math inline">\(\ref{ARMApq_Wold}\)</span>) se puede descomponer como en la forma de Wold:
<span class="math display">\[\begin{equation}
    \frac{\beta(L)}{\alpha(L)} = 1 + \psi_1 L + \psi_2 L^2 + \ldots
\end{equation}\]</span></p>
<p>Bajo los supuestos de estacionariedad del componente <span class="math inline">\(U_t\)</span>, los valores de la media y varianza de un proceso <span class="math inline">\(ARMA(p, q)\)</span> serán como describimos ahora. Para el caso de la media podemos partir de la ecuación (<span class="math inline">\(\ref{ARMApq_Wold}\)</span>) para generar:
<span class="math display">\[\begin{eqnarray}
    \mathbb{E}[X_t] &amp; = &amp; \mathbb{E}\left[ \frac{\delta}{1 - a_1 - a_2 - \ldots - a_p} + U_t + \psi_1 U_{t-1} + \psi_2 U_{t-2} + \ldots \right] \nonumber \\
    &amp; = &amp; \frac{\delta}{1 - a_1 - a_2 - \ldots - a_p} \nonumber \\
    &amp; = &amp; \mu
\end{eqnarray}\]</span></p>
<p>Esta expresión indica que en general un proceso <span class="math inline">\(ARMA(p, q)\)</span> converge a una media idéntica a la de un porceso <span class="math inline">\(AR(p)\)</span>. Para determinar la varianza utilizaremos la misma estratégia que hemos utilizado para otros modelos <span class="math inline">\(AR(p)\)</span> y <span class="math inline">\(MA(q)\)</span>.</p>
<p>Sin pérdida de generalidad podemos asumir que <span class="math inline">\(\delta = 0\)</span>, lo que implica que <span class="math inline">\(\mu = 0\)</span>, de lo que podemos establecer una expresión de autocovarianzas para cualquier valor <span class="math inline">\(\tau = 0, 1, 2, \ldots\)</span>:
<span class="math display">\[\begin{eqnarray}
    \gamma(\tau) &amp; = &amp; \mathbb{E}[X_{t-\tau} X_t] \nonumber \\
    &amp; = &amp; \mathbb{E}[X_{t-\tau} (\delta + a_1 X_{t - 1} + a_2 X_{t - 2} + \ldots + a_p X_{t - p} \nonumber \\
    &amp;   &amp; + U_t - b_1 U_{t - 1} - b_2  U_{t - 2} - \ldots - b_q  U_{t - q})] \nonumber \\
    &amp; = &amp; a_1 \gamma(\tau - 1) + a_2 \gamma(\tau - 2) + \ldots + a_p \gamma(\tau - p) \nonumber \\
    &amp;   &amp; + \mathbb{E}[X_{t-\tau} U_{t}] - b_1  \mathbb{E}[X_{t-\tau} U_{t-1}] - \ldots  - b_q  \mathbb{E}[X_{t-\tau} U_{t-q}]
\end{eqnarray}\]</span></p>
<p>Ahora veámos un ejemplo. Utilizaremos la serie de Pasajeros en vuelos nacionales de salida para estimar un <span class="math inline">\(ARMA(p, q)\)</span> mediante el método de máxima verosimilitud (ML). Antes de realizar el proceso de estimación consideremos una transformación de la serie en diferencias logaritmicas, ya que según la gráfica en la Figura (<span class="math inline">\(\ref{G_Pax_Nal}\)</span>) esa es la que puede ser estacionaria.</p>
<p>A continuación, estimaremos una <span class="math inline">\(ARMA(1, 1)\)</span> para la serie en diferencias logarimitcas (<span class="math inline">\(DLPaxNal_t\)</span>). También incorporaremos al análisis variables exogénas tales como dummies de estacionalidad. En particular, utilizaremos los meses de enero, febrero, julio y diciembre. No debe pasar desapercibido que un análisis de estacionalidad más formal debeería considerar todos los meses para separar del término de error la parte que puedee ser explicada por los ciclos estacionales.</p>
Así obtenemos el siguiente resultado:
Donde entre parentésis indicamos los errores estándar. Adicionalmente, reportamos el estadístico de Akaike (AIC). Finalmente, podemos determinar si las soluciones serán convergentes, para ello en la Figura <span class="math inline">\(\ref{G_Roots_ARMA11}\)</span> mostramos las raíces asociadas a cada uno de los polinomios. De la inspección visual podemos concluir que tenemos una solución convergente y estable. Por su parte la Figura (<span class="math inline">\(\ref{G_Residuals_ARMA11}\)</span>) muestra los residuales de la estimación del <span class="math inline">\(ARMA(1, 1)\)</span>.
<p>En lo que resta de este capítulo, utilizaremos la serie en diferencias logarítmicas de los pasajeros en vuelos nacionales de salida, <span class="math inline">\(DLPaxNal_t\)</span>, para discutir los ejemplos que ilustran cada uno de los puntos teóricos que a continuación exponemos.</p>
</div>
</div>
<div id="función-de-autocorrelación-parcial" class="section level2" number="4.4">
<h2>
<span class="header-section-number">4.4</span> Función de Autocorrelación Parcial<a class="anchor" aria-label="anchor" href="#funci%C3%B3n-de-autocorrelaci%C3%B3n-parcial"><i class="fas fa-link"></i></a>
</h2>
<p>Ahora introduciremos el concepto de Función de Autocorrelación Parcial (PACF, por sus siglas en inglés). Primero, dadas las condiciones de estabilidad y de convergencia, si suponemos que un proceso AR, MA, ARMA o ARIMA tienen toda la información de los rezagos de la serie en conjunto y toda la información de los promedio móviles del término de error, resulta importante construir una métrica para distinguir el efecto de <span class="math inline">\(X_{t - \tau}\)</span> o el efecto de <span class="math inline">\(U_{t - \tau}\)</span> (para cualquier <span class="math inline">\(\tau\)</span>) sobre <span class="math inline">\(X_t\)</span> de forma individual.</p>
<p>La idea es construir una métrica de la correlación que existe entre las diferentes varibles aleatorias, si para tal efecto se ha controlado el efecto del resto de la información. Así, podemos definir la ecuación que puede responder a este planteamiento como:
<span class="math display">\[\begin{equation}
    X_t = \phi_{k1} X_{t-1} + \phi_{k2} X_{t-2} + \ldots + \phi_{kk} X_{t-k} + U_t
    \label{PACF_Eq}
\end{equation}\]</span></p>
<p>Donde <span class="math inline">\(\phi_{ki}\)</span> es el coeficiente de la variable dada con el rezago <span class="math inline">\(i\)</span> si el proceso tiene un órden <span class="math inline">\(k\)</span>. Así, los coeficientes <span class="math inline">\(\phi_{kk}\)</span> son los coeficientes de la autocorrelación parcial (considerando un proceso AR(k)). Observemos que la autocorrelaicón parcial mide la correlación entre <span class="math inline">\(X_t\)</span> y <span class="math inline">\(X_{t-k}\)</span> que se mantiene cuando el efecto de las variables <span class="math inline">\(X_{t-1}\)</span>, <span class="math inline">\(X_{t-2}\)</span>, <span class="math inline">\(\ldots\)</span> y <span class="math inline">\(X_{t-k-1}\)</span> en <span class="math inline">\(X_{t}\)</span> y <span class="math inline">\(X_{t-k}\)</span> ha sido eliminado.</p>
<p>Dada la expresión considerada en la ecuación (<span class="math inline">\(\ref{PACF_Eq}\)</span>), podemos resolver el problema de establecer el valor de cada <span class="math inline">\(\phi_{ki}\)</span> mediante la solución del sistema que se representa en lo siguiente:
<span class="math display">\[\begin{equation}
    \left[
    \begin{array}{c}
        \rho(1) \\
        \rho(2) \\
        \vdots \\
        \rho(k)
    \end{array}
    \right]
    =
    \left[
    \begin{array}{c c c c}
        1 &amp; \rho(1) &amp; \ldots &amp; \rho(k - 1)\\
        \rho(1) &amp; 1 &amp; \ldots &amp; \rho(k - 2)\\
        \rho(2) &amp; \rho(1) &amp; \ldots &amp; \rho(k - 3)\\
        \vdots &amp; \vdots &amp; \ldots &amp; \vdots\\
        \rho(k - 1) &amp; \rho(k - 2) &amp; \ldots &amp; 1\\
    \end{array}
    \right]
    \left[
    \begin{array}{c}
        \phi_{k1} \\
        \phi_{k2} \\
        \phi_{k3} \\
        \vdots \\
        \phi_{kk} \\
    \end{array}
    \right]
\end{equation}\]</span></p>
<p>Del cual se puede derivar una solución, resoviendo por el método de cramer, o cualquier otro método que consideremos y que permita calcular la solución de sistemas de ecuaciones.</p>
<p>Posterior al análisis analítico platearemos un enfoque para interpretar las funciones de autocorrelación y autocorrelación parcial. Este enfoque pretende aportar al principio de parcimonia, en el cual podemos identificar el número de parámetros que posiblemente puede describir mejor a la serie en un modelo ARMA(p, q).</p>
En el Cuadro <span class="math inline">\(\ref{ACF_PACF}\)</span> se muestra un resumen de las caranterísticas que debemos observar para determinar el número de parámetros de cada uno de los componentes AR y MA. Lo anterior por observación de las funciones de autocorrelación y autocorrelación parcial. Este enfoque no es el más formal, más adelante implemtaremos uno más formal y que puede ser más claro de cómo determinar el númeto de parámetros.
Continuando con el ejemplo en la Figura (<span class="math inline">\(\ref{G_ACF_PACF}\)</span>) mostramos tanto la Función de Autocorrelación como la Función de Autocorrelación Parcial. En esta identificamos que ambas gráficas muestran que el modelo que explica a la variable <span class="math inline">\(DLPaxNal_t\)</span> tiene tanto componentes AR como MA. Sin embargo, dado lo errático del comportamiento de ambas funciones, resulta complicado determinar cuál sería un buen número de parametros <span class="math inline">\(p\)</span> y <span class="math inline">\(q\)</span> a considerar en el <span class="math inline">\(ARMA(p,q)\)</span>. Por esta razón a continuación platearemos algunas pruebas más formales para determinar dichos parámetros.
</div>
<div id="selección-de-las-constantes-p-q-d-en-un-arp-un-maq-un-armap-q-o-un-arimap-d-q" class="section level2" number="4.5">
<h2>
<span class="header-section-number">4.5</span> Selección de las constantes p, q, d en un AR(p), un MA(q), un ARMA(p, q) o un ARIMA(p, d, q)<a class="anchor" aria-label="anchor" href="#selecci%C3%B3n-de-las-constantes-p-q-d-en-un-arp-un-maq-un-armap-q-o-un-arimap-d-q"><i class="fas fa-link"></i></a>
</h2>
<p>Respecto de cómo estimar un proceso ARMA(p, q) –en general utilizaremos este modelo para discutir, pero lo planteado en esta sección es igualmente aplicable en cualquier otro caso como aquellos modelos que incluyen variables exogénas– existen diversas formas de estimar los paramétros <span class="math inline">\(a_i\)</span> y <span class="math inline">\(b_i\)</span>: i) por máxima verosimilitd y ii) por mínimos cuadrados órdinarios. El primer caso requiere que conozcamos la distribución del proceso aleatorio <span class="math inline">\(U_t\)</span>. El segundo, por el contrario, no requiere el mismo supuesto. No obstante, para el curso utilizaremos el método de máxima verosimilitud.</p>
<p>Otra duda que debe quedar hasta el momento es ¿cómo determinar el orden <span class="math inline">\(p\)</span> y <span class="math inline">\(q\)</span> del proceso ARMA(p, q)? La manera más convencional y formal que existe para tal efecto es utilizar los criterios de información. Así, el orden se elije de acuerdo a aquel críterio de información que resulta ser el mínimo. En el caso de <span class="math inline">\(d\)</span> se selecciona revisando la gráfica que parezca más estacionaria–más adelante mostraremos un proceso más formal para su selección.</p>
Los criterios de información más comunes son los siguientes:
<p>Donde <span class="math inline">\(\hat{U}_t^{(p)}\)</span> son los residuales estimados mediante un proceso ARIMA y <span class="math inline">\(m\)</span> es el número de parametros estimados: <span class="math inline">\(m = p + q + 0 + 1\)</span> (ya que asumimos que <span class="math inline">\(d = 0\)</span>). Una propiedad que no se debe perder de vista es que los criterios de información cumplen la siguiente relación:
<span class="math display">\[\begin{equation}
    orden(SC) \leq orden(HQ) \leq orden(AIC)
\end{equation}\]</span></p>
<p>Por esta razón, durante el curso solo utilizaremos el criterio se Akaike para determinar el orden óptimo del proceso ARMA, ya que ello garantiza el orden más grande posible.</p>
<p>Ahora veamos un ejemplo de estimación del número de rezagos optimo de un <span class="math inline">\(ARMA(p, q)\)</span>. Retomemos la serie en diferencias logarítmicas de los pasajeros en vuelos nacionales de salidas, pero ahora incluiremos la variables exógenas de dummies estacionales: enero, febrero, julio y diciembre.</p>
<p>Como mencionamos, las gráficas de las funciones de autocorrelación permiten observar el valor de la correlación existente entre la variable en el momento <span class="math inline">\(t\)</span> con cada uno de los rezagos. Incluso la Función de Autocorrelación Parcial puede ayudar a determinar el número máximo de rezagos que se debe incluir en el proceso <span class="math inline">\(AR(p)\)</span>. No obstante, una métrica más formal es el uso de los criterios de información. En nuestro caso, dado lo discutido, sólo utilizareemos el criterio de Akaike.</p>
Al respecto, en el Cuadro (<span class="math inline">\(\ref{Selec_ARMApq}\)</span>) reportamos el criterio de Akaike que resultan de aplicar dicho criterio a los residuales resultantes de cada combinación de procesos <span class="math inline">\(ARMA(p, q)\)</span>. La forma de escoger será aquel modelo que reporta el criterio de Akaike menor. En la cuarta columna de la tabla se señala el valor del criterio de información que resulta ser el mínimo de todos los posibles.
<p>El Cuadro (<span class="math inline">\(\ref{Selec_ARMApq}\)</span>) reporta los resultados para 36 diferentes modelos, todos incluyen variables exogenas. Como resultado del análisis concluimos que el modelo más adecuado es el 24, el cual considera un <span class="math inline">\(ARMA(4, 6)\)</span>, con variables dummies para controlar la estacionalidad de los meses de enero, febrero, julio y diciembre. En el Cuadro (<span class="math inline">\(\ref{Result_ARMApq}\)</span>) mostramos los resutados del modelo.</p>
No obstante, una inspección de los residuales del modelo nos permite sospechar que requiere de incluir un par de dummies más. Ambas, asociadas con la caída del transporte aéreo en 2009, principalmente asociado con la crisis mundial de ese año. La Figura (<span class="math inline">\(\ref{G_Residuals_ARMA46}\)</span>) muestra los residuales mencionados.
Una vez incluidas dos dummies más para mayo y junio de 2009, analizamos un total de 36 modelos ARMA y determinamos que el orden que minimizza el criterio de Akaike es un <span class="math inline">\(ARMA(4, 6)\)</span>. El Cuadro (<span class="math inline">\(\ref{Result_ARMApq}\)</span>) muestra los resultados para este nuevo modelo. No lo motramos en esta sección, pero ambos modelos reportados tienen raices de sus respectivos polinomios característicos menores a 1 en valor absoluto. En la Figura <span class="math inline">\(\ref{G_Residuals_ARMA46_D}\)</span> mostramos los residuales ahora ajustados por las dummies de mayo y junio de 2009.
</div>
<div id="pronósticos" class="section level2" number="4.6">
<h2>
<span class="header-section-number">4.6</span> Pronósticos<a class="anchor" aria-label="anchor" href="#pron%C3%B3sticos"><i class="fas fa-link"></i></a>
</h2>
<p>Para pronósticar el valor de la serie es necesario determinar cuál es el valor esperado de la serie en un momento <span class="math inline">\(t + \tau\)</span> condicional en que ésta se comporta como un <span class="math inline">\(AR(p)\)</span>, un <span class="math inline">\(MA(q)\)</span> o un <span class="math inline">\(ARMA(p, q)\)</span> y a que los valores antes de <span class="math inline">\(t\)</span> están dados. Por lo que el pronóstico de la serie estará dado por una expresión:
<span class="math display">\[\begin{eqnarray}
    \mathbb{E}_t[X_{t+\tau}] = \delta + a_1 \mathbb{E}_t[X_{t+\tau-1}] + a_2 \mathbb{E}_t[X_{t+\tau-2}] + \ldots + + a_p \mathbb{E}_t[X_{t+\tau-p}]
    \label{ARMApq_For}
\end{eqnarray}\]</span></p>
<p>Lo anterior para todo <span class="math inline">\(\tau = 0, 1, 2, \ldots\)</span> y considerando que los componentes MA(q) en la eucación (<span class="math inline">\(\ref{ARMApq_For}\)</span>) son cero dado que para todo valor <span class="math inline">\(t + \tau\)</span> es cierto que <span class="math inline">\(\mathbb{E}_t[U_{t+\tau}]\)</span>.</p>
Continuando con el ejemplo, en la Figura (<span class="math inline">\(\ref{Pax_Nal_f}\)</span>) mostramos el resultado del pronóstico de la serie a partir del modelo ARMA(4, 6) que hemos discutido anteriormente.

</div>
</div>













  <div class="chapter-nav">
<div class="prev"><a href="modelos-de-series-de-tiempo-estacionarias.html"><span class="header-section-number">3</span> Modelos de Series de Tiempo Estacionarias</a></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#procesos-estacionarios-univariados"><span class="header-section-number">4</span> Procesos estacionarios univariados</a></li>
<li>
<a class="nav-link" href="#procesos-autoregresivos-ar"><span class="header-section-number">4.1</span> Procesos Autoregresivos (AR)</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#ar1"><span class="header-section-number">4.1.1</span> AR(1)</a></li>
<li><a class="nav-link" href="#ar2"><span class="header-section-number">4.1.2</span> AR(2)</a></li>
<li><a class="nav-link" href="#arp"><span class="header-section-number">4.1.3</span> AR(p)</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#procesos-de-medias-m%C3%B3viles-ma"><span class="header-section-number">4.2</span> Procesos de Medias Móviles (MA)</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#ma1"><span class="header-section-number">4.2.1</span> MA(1)</a></li>
<li><a class="nav-link" href="#maq"><span class="header-section-number">4.2.2</span> MA(q)</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#procesos-armap-q-y-arimap-d-q"><span class="header-section-number">4.3</span> Procesos ARMA(p, q) y ARIMA(p, d, q)</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#arma1-1"><span class="header-section-number">4.3.1</span> ARMA(1, 1)</a></li>
<li><a class="nav-link" href="#armap-q"><span class="header-section-number">4.3.2</span> ARMA(p, q)</a></li>
</ul>
</li>
<li><a class="nav-link" href="#funci%C3%B3n-de-autocorrelaci%C3%B3n-parcial"><span class="header-section-number">4.4</span> Función de Autocorrelación Parcial</a></li>
<li><a class="nav-link" href="#selecci%C3%B3n-de-las-constantes-p-q-d-en-un-arp-un-maq-un-armap-q-o-un-arimap-d-q"><span class="header-section-number">4.5</span> Selección de las constantes p, q, d en un AR(p), un MA(q), un ARMA(p, q) o un ARIMA(p, d, q)</a></li>
<li><a class="nav-link" href="#pron%C3%B3sticos"><span class="header-section-number">4.6</span> Pronósticos</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="git@github.com:emilianoprzcls/bookdown-notas-series-de-tiempo.git/blob/master/03-PE_Univariados.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="git@github.com:emilianoprzcls/bookdown-notas-series-de-tiempo.git/edit/master/03-PE_Univariados.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Notas de Clase: Series de Tiempo</strong>" was written by Benjamín Oliva, Omar Alfaro-Rivera y Emiliano Pérez Caullieres. It was last built on 2022-07-14.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
